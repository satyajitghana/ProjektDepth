{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06-DepthModel-ModelZoo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO1cEc4YYRKqipyBjABWZHJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f314f899dc84aa993eada03b0e42571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b4a107cd2d874413bb430bce4c61d856",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b4b72decdee14c38b056499138511151",
              "IPY_MODEL_b445416362c140aaa536d41b59f0a6a0"
            ]
          }
        },
        "b4a107cd2d874413bb430bce4c61d856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4b72decdee14c38b056499138511151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab6c33f78dcc44d198d2c4e273cf543f",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 6250,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 18,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85a55a0e00ca4813976dbff5d9fcc508"
          }
        },
        "b445416362c140aaa536d41b59f0a6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08ad2f6aa44746af945e434172841b93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 18/6250 [00:31&lt;2:49:12,  1.63s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99aca92e6e5a47908cacaed3286b4271"
          }
        },
        "ab6c33f78dcc44d198d2c4e273cf543f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85a55a0e00ca4813976dbff5d9fcc508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08ad2f6aa44746af945e434172841b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99aca92e6e5a47908cacaed3286b4271": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e836802abf842ec8f09f7840e5523a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e8c557c5d4b34558b82a7a65c495b371",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d14b91c924064e19ad99baf90aaa8912",
              "IPY_MODEL_e45f5706eb594834b7e449f20272c48e"
            ]
          }
        },
        "e8c557c5d4b34558b82a7a65c495b371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d14b91c924064e19ad99baf90aaa8912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aed8d19fc841452d9a5f58fbb45c75d9",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_518c152f51d7433fb8b62eebc0ab2b8d"
          }
        },
        "e45f5706eb594834b7e449f20272c48e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e9b313612e14c1ab0412877b167e86c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [14:33&lt;00:00, 53.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a114baf9297b46c9b76b8efa4aa21031"
          }
        },
        "aed8d19fc841452d9a5f58fbb45c75d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "518c152f51d7433fb8b62eebc0ab2b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e9b313612e14c1ab0412877b167e86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a114baf9297b46c9b76b8efa4aa21031": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyajitghana/ProjektDepth/blob/master/notebooks/06_DepthModel_ModelZoo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjK5_PAvML5V",
        "colab_type": "text"
      },
      "source": [
        "# DepthModel - Model Zoo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fkKn9GbFE_c",
        "colab_type": "code",
        "outputId": "e2c0d51a-96f9-45f2-95da-a2c57fabc942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! pip install funcy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: funcy in /usr/local/lib/python3.6/dist-packages (1.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlS79vV4FKIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import funcy\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def summary(model, input_size, batch_size=-1, device=\"cuda\"):\n",
        "\n",
        "    def register_hook(module):\n",
        "\n",
        "        def hook(module, input, output):\n",
        "            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
        "            module_idx = len(summary)\n",
        "\n",
        "            m_key = \"%s-%i\" % (class_name, module_idx + 1)\n",
        "            summary[m_key] = OrderedDict()\n",
        "            summary[m_key][\"input_shape\"] = list(input[0].size())\n",
        "            summary[m_key][\"input_shape\"][0] = batch_size\n",
        "            if isinstance(output, (list, tuple)):\n",
        "                summary[m_key][\"output_shape\"] = [\n",
        "                    [-1] + list(o.size())[1:] for o in output\n",
        "                ]\n",
        "            else:\n",
        "                summary[m_key][\"output_shape\"] = list(output.size())\n",
        "                summary[m_key][\"output_shape\"][0] = batch_size\n",
        "\n",
        "            params = 0\n",
        "            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
        "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
        "                summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
        "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
        "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
        "            summary[m_key][\"nb_params\"] = params\n",
        "\n",
        "        if (\n",
        "            not isinstance(module, nn.Sequential)\n",
        "            and not isinstance(module, nn.ModuleList)\n",
        "            and not (module == model)\n",
        "        ):\n",
        "            hooks.append(module.register_forward_hook(hook))\n",
        "\n",
        "    device = device.lower()\n",
        "    assert device in [\n",
        "        \"cuda\",\n",
        "        \"cpu\",\n",
        "    ], \"Input device is not valid, please specify 'cuda' or 'cpu'\"\n",
        "\n",
        "    if device == \"cuda\" and torch.cuda.is_available():\n",
        "        dtype = torch.cuda.FloatTensor\n",
        "    else:\n",
        "        dtype = torch.FloatTensor\n",
        "\n",
        "    # multiple inputs to the network\n",
        "    if isinstance(input_size, tuple):\n",
        "        input_size = [input_size]\n",
        "\n",
        "    # batch_size of 2 for batchnorm\n",
        "    x = [torch.rand(2, *in_size).type(dtype) for in_size in input_size]\n",
        "    # print(type(x[0]))\n",
        "\n",
        "    # create properties\n",
        "    summary = OrderedDict()\n",
        "    hooks = []\n",
        "\n",
        "    # register hook\n",
        "    model.apply(register_hook)\n",
        "\n",
        "    # make a forward pass\n",
        "    # print(x.shape)\n",
        "    model(*x)\n",
        "\n",
        "    # remove these hooks\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "\n",
        "    print(\"----------------------------------------------------------------\")\n",
        "    line_new = \"{:>20}  {:>25} {:>15}\".format(\"Layer (type)\", \"Output Shape\", \"Param #\")\n",
        "    print(line_new)\n",
        "    print(\"================================================================\")\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total_output = 0\n",
        "    for layer in summary:\n",
        "        # input_shape, output_shape, trainable, nb_params\n",
        "        line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
        "            layer,\n",
        "            str(summary[layer][\"output_shape\"]),\n",
        "            \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
        "        )\n",
        "        total_output += np.prod(list(funcy.flatten(summary[layer][\"output_shape\"])))\n",
        "        print(line_new)\n",
        "\n",
        "    # assume 4 bytes/number (float on cuda).\n",
        "    total_input_size = abs(sum([np.prod(input_item) for input_item in input_size]) * batch_size * 4. / (1024 ** 2.))\n",
        "    total_output_size = abs(2. * total_output * 4. / (1024 ** 2.))  # x2 for gradients\n",
        "    total_params_size = abs(total_params * 4. / (1024 ** 2.))\n",
        "    total_size = total_params_size + total_output_size + total_input_size\n",
        "\n",
        "    print(\"================================================================\")\n",
        "    print(\"Total params: {0:,}\".format(total_params))\n",
        "    print(\"Trainable params: {0:,}\".format(trainable_params))\n",
        "    print(\"Non-trainable params: {0:,}\".format(total_params - trainable_params))\n",
        "    print(\"----------------------------------------------------------------\")\n",
        "    print(\"Input size (MB): %0.2f\" % total_input_size)\n",
        "    print(\"Forward/backward pass size (MB): %0.2f\" % total_output_size)\n",
        "    print(\"Params size (MB): %0.2f\" % total_params_size)\n",
        "    print(\"Estimated Total Size (MB): %0.2f\" % total_size)\n",
        "    print(\"----------------------------------------------------------------\")\n",
        "    # return summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q_prQlwBq0Z",
        "colab_type": "code",
        "outputId": "d2e1b480-c269-46ec-bb8a-7eb6f3b3944e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 18 09:19:33 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R84_NKeqMOOx",
        "colab_type": "text"
      },
      "source": [
        "Here we make all the different models we could use with our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8X4wrrws05q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm\n",
        "import gc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY0PbvvJB8I7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNG0GjXL2CH5",
        "colab_type": "text"
      },
      "source": [
        "# Custom Unet - ResNet Backbone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrqqVBLpXuiC",
        "colab_type": "text"
      },
      "source": [
        "Note: All the Resnet Blocks use the ResNetV2 Architecure, i.e. preactivated blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ520rBca7al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResDoubleConv(nn.Module):\n",
        "    '''Basic DoubleConv of a ResNetV2'''\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MouqhIgG8K-m",
        "colab_type": "code",
        "outputId": "fda2d4d5-b2c7-4136-ae35-e2e94083678e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "summary(ResDoubleConv(512, 1024).to(device), (512, 12, 12))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "       BatchNorm2d-1          [-1, 512, 12, 12]           1,024\n",
            "              ReLU-2          [-1, 512, 12, 12]               0\n",
            "            Conv2d-3         [-1, 1024, 12, 12]       4,718,592\n",
            "       BatchNorm2d-4         [-1, 1024, 12, 12]           2,048\n",
            "              ReLU-5         [-1, 1024, 12, 12]               0\n",
            "            Conv2d-6         [-1, 1024, 12, 12]       9,437,184\n",
            "================================================================\n",
            "Total params: 14,158,848\n",
            "Trainable params: 14,158,848\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.28\n",
            "Forward/backward pass size (MB): 5.62\n",
            "Params size (MB): 54.01\n",
            "Estimated Total Size (MB): 59.92\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkQoood2XV-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResDownBlock(nn.Module):\n",
        "    '''Basic DownBlock of a ResNetV2'''\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.double_conv = ResDoubleConv(in_channels, out_channels)\n",
        "\n",
        "        self.proj_layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "        self.down_sample = nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self, input):\n",
        "        identity = self.proj_layer(input)\n",
        "        out = self.double_conv(input)\n",
        "        out = out + identity\n",
        "\n",
        "        del identity\n",
        "\n",
        "        return self.down_sample(out), out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw_wwtDx8a-Z",
        "colab_type": "code",
        "outputId": "b17ad768-21d3-49e3-a4b0-0986cc0be885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "summary(ResDownBlock(256, 512).to(device), (256, 24, 24))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 512, 24, 24]         131,072\n",
            "       BatchNorm2d-2          [-1, 512, 24, 24]           1,024\n",
            "       BatchNorm2d-3          [-1, 256, 24, 24]             512\n",
            "              ReLU-4          [-1, 256, 24, 24]               0\n",
            "            Conv2d-5          [-1, 512, 24, 24]       1,179,648\n",
            "       BatchNorm2d-6          [-1, 512, 24, 24]           1,024\n",
            "              ReLU-7          [-1, 512, 24, 24]               0\n",
            "            Conv2d-8          [-1, 512, 24, 24]       2,359,296\n",
            "     ResDoubleConv-9          [-1, 512, 24, 24]               0\n",
            "        MaxPool2d-10          [-1, 512, 12, 12]               0\n",
            "================================================================\n",
            "Total params: 3,672,576\n",
            "Trainable params: 3,672,576\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.56\n",
            "Forward/backward pass size (MB): 18.56\n",
            "Params size (MB): 14.01\n",
            "Estimated Total Size (MB): 33.13\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04MXRmtDXmz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResUpBlock(nn.Module):\n",
        "    '''Basic UpBlock of a ResNetV2'''\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.upsample_1 = nn.PixelShuffle(2)\n",
        "        self.upsample_2 = nn.PixelShuffle(2)\n",
        "        self.upsample_3 = nn.PixelShuffle(2)\n",
        "        self.upsample_4 = nn.PixelShuffle(2)\n",
        "\n",
        "        self.upscale = nn.Upsample(scale_factor=2, mode='bilinear')\n",
        "\n",
        "        self.double_conv = ResDoubleConv(in_channels, out_channels)\n",
        "\n",
        "        self.proj_layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, down_input, skip_input, decoder_input=None):\n",
        "\n",
        "        upsampled = [self.upsample_1(down_input), self.upsample_2(down_input), self.upsample_3(down_input), self.upsample_4(down_input)]\n",
        "        x = torch.cat(upsampled, dim=1)\n",
        "        x = torch.cat([x, skip_input], dim=1)\n",
        "\n",
        "        if decoder_input is not None:\n",
        "            x = torch.cat([x, decoder_input], dim=1)\n",
        "\n",
        "        identity = self.proj_layer(x)\n",
        "\n",
        "        out = self.double_conv(x) + identity\n",
        "\n",
        "        del identity, upsampled, x\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM8oY9nP8ITK",
        "colab_type": "code",
        "outputId": "b4b426c4-4dae-4441-e11b-ab045a6c5be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "summary(ResUpBlock(512 + 256, 256).to(device), [(512, 24, 24), (256, 48, 48)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "      PixelShuffle-1          [-1, 128, 48, 48]               0\n",
            "      PixelShuffle-2          [-1, 128, 48, 48]               0\n",
            "      PixelShuffle-3          [-1, 128, 48, 48]               0\n",
            "      PixelShuffle-4          [-1, 128, 48, 48]               0\n",
            "            Conv2d-5          [-1, 256, 48, 48]         196,608\n",
            "       BatchNorm2d-6          [-1, 256, 48, 48]             512\n",
            "       BatchNorm2d-7          [-1, 768, 48, 48]           1,536\n",
            "              ReLU-8          [-1, 768, 48, 48]               0\n",
            "            Conv2d-9          [-1, 256, 48, 48]       1,769,472\n",
            "      BatchNorm2d-10          [-1, 256, 48, 48]             512\n",
            "             ReLU-11          [-1, 256, 48, 48]               0\n",
            "           Conv2d-12          [-1, 256, 48, 48]         589,824\n",
            "    ResDoubleConv-13          [-1, 256, 48, 48]               0\n",
            "================================================================\n",
            "Total params: 2,558,464\n",
            "Trainable params: 2,558,464\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.38\n",
            "Forward/backward pass size (MB): 67.50\n",
            "Params size (MB): 9.76\n",
            "Estimated Total Size (MB): 80.63\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6SKnfrTKxAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.res_down1 = ResDownBlock(6, 64)     # H / 2   ; input = 192x192x6 ; output = 96x96x64   ; skip1 = 192x192x64\n",
        "        self.res_down2 = ResDownBlock(64, 128)   # H / 4   ; input = 96x96x64  ; output = 48x48x128  ; skip2 = 96x96x128\n",
        "        self.res_down3 = ResDownBlock(128, 256)  # H / 8   ; input = 48x48x128 ; output = 24x24x256  ; skip3 = 48x48x256\n",
        "        self.res_down4 = ResDownBlock(256, 512)  # H / 16  ; input = 24x24x256 ; output = 12x12x512  ; skip4 = 24x24x512 \n",
        "\n",
        "        # Bridge\n",
        "        self.bridge =  ResDoubleConv(512, 512)\n",
        "\n",
        "        # Depth Decoder\n",
        "        self.d_res_up4 = ResUpBlock(512 + 512, 512)  # H / 8  ; input = 24x24x1024(upscaled)  24x24x512(skip4)  ; output = 24x24x512(dskip4)\n",
        "        self.d_res_up3 = ResUpBlock(512 + 256, 256)   # H / 4  ; input = 48x48x512(upscaled)   48x48x256(skip3)  ; output = 48x48x256(dskip3)\n",
        "        self.d_res_up2 = ResUpBlock(256 + 128, 128)   # H / 2  ; input = 96x96x256(upscaled)   96x96x128(skip2)  ; output = 96x96x128(dskip2)\n",
        "        self.d_res_up1 = ResUpBlock(128 + 64, 64)     # H / 1  ; input = 192x192x128(upscaled) 192x192x64(skip1) ; output = 192x192x64(dskip1)\n",
        "\n",
        "        # Depth Output\n",
        "        self.depth_output = nn.Conv2d(64, 1, kernel_size=1, stride=1, bias=False)  # output = 192x192x1\n",
        "\n",
        "        # Segmentation Decoder\n",
        "        self.s_res_up4 = ResUpBlock(512 + 512 + 512, 512)  # H / 8  ; input = 24x24x1024(upscaled)  24x24x512(dskip4)  24x24x512(skip4)  ; output = 24x24x512\n",
        "        self.s_res_up3 = ResUpBlock(512 + 256 + 256, 256)   # H / 4  ; input = 48x48x512(upscaled)   48x48x256(dskip3)  48x48x256(skip3)  ; output = 48x48x256\n",
        "        self.s_res_up2 = ResUpBlock(256 + 128 + 128, 128)   # H / 2  ; input = 96x96x256(upscaled)   96x96x128(dskip2)  96x96x128(skip2)  ; output = 96x96x128\n",
        "        self.s_res_up1 = ResUpBlock(128 + 64 + 64, 64)      # H / 1  ; input = 192x192x128(upscaled) 192x192x64(dskip1) 192x192x64(skip1) ; output = 192x192x64\n",
        "\n",
        "\n",
        "        # Segmentation Output\n",
        "        self.segment_output = nn.Conv2d(64, 1, kernel_size=1, stride=1, bias=False) # output = 192x192x1\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        # Encoder\n",
        "        rd1, skip1_out = self.res_down1(input)\n",
        "        rd2, skip2_out = self.res_down2(rd1)\n",
        "        rd3, skip3_out = self.res_down3(rd2)\n",
        "        rd4, skip4_out = self.res_down4(rd3)\n",
        "\n",
        "        # Bridge\n",
        "        bridge = self.bridge(rd4)\n",
        "\n",
        "        # Depth Decoder\n",
        "        dru4 = self.d_res_up4(bridge, skip4_out)\n",
        "        dru3 = self.d_res_up3(dru4, skip3_out)\n",
        "        dru2 = self.d_res_up2(dru3, skip2_out)\n",
        "        dru1 = self.d_res_up1(dru2, skip1_out)\n",
        "\n",
        "        d_out = self.depth_output(dru1)\n",
        "\n",
        "        # Segmentation Decoder\n",
        "        sru4 = self.s_res_up4(bridge, skip4_out, dru4)\n",
        "        sru3 = self.s_res_up3(sru4, skip3_out, dru3)\n",
        "        sru2 = self.s_res_up2(sru3, skip2_out, dru2)\n",
        "        sru1 = self.s_res_up1(sru2, skip1_out, dru1)\n",
        "\n",
        "\n",
        "        s_out = self.segment_output(sru1)\n",
        "\n",
        "\n",
        "        return d_out, s_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htwlSExZ6rGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ResUNet().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osL4kDmV7ZMn",
        "colab_type": "code",
        "outputId": "0cf61750-a4ee-4b35-df08-fd295baa49f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "summary(model, (6, 192, 192))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 192, 192]             384\n",
            "       BatchNorm2d-2         [-1, 64, 192, 192]             128\n",
            "       BatchNorm2d-3          [-1, 6, 192, 192]              12\n",
            "              ReLU-4          [-1, 6, 192, 192]               0\n",
            "            Conv2d-5         [-1, 64, 192, 192]           3,456\n",
            "       BatchNorm2d-6         [-1, 64, 192, 192]             128\n",
            "              ReLU-7         [-1, 64, 192, 192]               0\n",
            "            Conv2d-8         [-1, 64, 192, 192]          36,864\n",
            "     ResDoubleConv-9         [-1, 64, 192, 192]               0\n",
            "        MaxPool2d-10           [-1, 64, 96, 96]               0\n",
            "     ResDownBlock-11  [[-1, 64, 96, 96], [-1, 64, 192, 192]]               0\n",
            "           Conv2d-12          [-1, 128, 96, 96]           8,192\n",
            "      BatchNorm2d-13          [-1, 128, 96, 96]             256\n",
            "      BatchNorm2d-14           [-1, 64, 96, 96]             128\n",
            "             ReLU-15           [-1, 64, 96, 96]               0\n",
            "           Conv2d-16          [-1, 128, 96, 96]          73,728\n",
            "      BatchNorm2d-17          [-1, 128, 96, 96]             256\n",
            "             ReLU-18          [-1, 128, 96, 96]               0\n",
            "           Conv2d-19          [-1, 128, 96, 96]         147,456\n",
            "    ResDoubleConv-20          [-1, 128, 96, 96]               0\n",
            "        MaxPool2d-21          [-1, 128, 48, 48]               0\n",
            "     ResDownBlock-22  [[-1, 128, 48, 48], [-1, 128, 96, 96]]               0\n",
            "           Conv2d-23          [-1, 256, 48, 48]          32,768\n",
            "      BatchNorm2d-24          [-1, 256, 48, 48]             512\n",
            "      BatchNorm2d-25          [-1, 128, 48, 48]             256\n",
            "             ReLU-26          [-1, 128, 48, 48]               0\n",
            "           Conv2d-27          [-1, 256, 48, 48]         294,912\n",
            "      BatchNorm2d-28          [-1, 256, 48, 48]             512\n",
            "             ReLU-29          [-1, 256, 48, 48]               0\n",
            "           Conv2d-30          [-1, 256, 48, 48]         589,824\n",
            "    ResDoubleConv-31          [-1, 256, 48, 48]               0\n",
            "        MaxPool2d-32          [-1, 256, 24, 24]               0\n",
            "     ResDownBlock-33  [[-1, 256, 24, 24], [-1, 256, 48, 48]]               0\n",
            "           Conv2d-34          [-1, 512, 24, 24]         131,072\n",
            "      BatchNorm2d-35          [-1, 512, 24, 24]           1,024\n",
            "      BatchNorm2d-36          [-1, 256, 24, 24]             512\n",
            "             ReLU-37          [-1, 256, 24, 24]               0\n",
            "           Conv2d-38          [-1, 512, 24, 24]       1,179,648\n",
            "      BatchNorm2d-39          [-1, 512, 24, 24]           1,024\n",
            "             ReLU-40          [-1, 512, 24, 24]               0\n",
            "           Conv2d-41          [-1, 512, 24, 24]       2,359,296\n",
            "    ResDoubleConv-42          [-1, 512, 24, 24]               0\n",
            "        MaxPool2d-43          [-1, 512, 12, 12]               0\n",
            "     ResDownBlock-44  [[-1, 512, 12, 12], [-1, 512, 24, 24]]               0\n",
            "      BatchNorm2d-45          [-1, 512, 12, 12]           1,024\n",
            "             ReLU-46          [-1, 512, 12, 12]               0\n",
            "           Conv2d-47          [-1, 512, 12, 12]       2,359,296\n",
            "      BatchNorm2d-48          [-1, 512, 12, 12]           1,024\n",
            "             ReLU-49          [-1, 512, 12, 12]               0\n",
            "           Conv2d-50          [-1, 512, 12, 12]       2,359,296\n",
            "    ResDoubleConv-51          [-1, 512, 12, 12]               0\n",
            "================================================================\n",
            "Total params: 9,582,988\n",
            "Trainable params: 9,582,988\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.84\n",
            "Forward/backward pass size (MB): 14100212.25\n",
            "Params size (MB): 36.56\n",
            "Estimated Total Size (MB): 14100249.65\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpmBYafZFp_e",
        "colab_type": "code",
        "outputId": "06d2968b-166a-49fb-f652-9289c878b3ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "summary(model, (6, 192, 192))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 192, 192]             384\n",
            "       BatchNorm2d-2         [-1, 64, 192, 192]             128\n",
            "       BatchNorm2d-3          [-1, 6, 192, 192]              12\n",
            "              ReLU-4          [-1, 6, 192, 192]               0\n",
            "            Conv2d-5         [-1, 64, 192, 192]           3,456\n",
            "       BatchNorm2d-6         [-1, 64, 192, 192]             128\n",
            "              ReLU-7         [-1, 64, 192, 192]               0\n",
            "            Conv2d-8         [-1, 64, 192, 192]          36,864\n",
            "     ResDoubleConv-9         [-1, 64, 192, 192]               0\n",
            "        MaxPool2d-10           [-1, 64, 96, 96]               0\n",
            "     ResDownBlock-11  [[-1, 64, 96, 96], [-1, 64, 192, 192]]               0\n",
            "           Conv2d-12          [-1, 128, 96, 96]           8,192\n",
            "      BatchNorm2d-13          [-1, 128, 96, 96]             256\n",
            "      BatchNorm2d-14           [-1, 64, 96, 96]             128\n",
            "             ReLU-15           [-1, 64, 96, 96]               0\n",
            "           Conv2d-16          [-1, 128, 96, 96]          73,728\n",
            "      BatchNorm2d-17          [-1, 128, 96, 96]             256\n",
            "             ReLU-18          [-1, 128, 96, 96]               0\n",
            "           Conv2d-19          [-1, 128, 96, 96]         147,456\n",
            "    ResDoubleConv-20          [-1, 128, 96, 96]               0\n",
            "        MaxPool2d-21          [-1, 128, 48, 48]               0\n",
            "     ResDownBlock-22  [[-1, 128, 48, 48], [-1, 128, 96, 96]]               0\n",
            "           Conv2d-23          [-1, 256, 48, 48]          32,768\n",
            "      BatchNorm2d-24          [-1, 256, 48, 48]             512\n",
            "      BatchNorm2d-25          [-1, 128, 48, 48]             256\n",
            "             ReLU-26          [-1, 128, 48, 48]               0\n",
            "           Conv2d-27          [-1, 256, 48, 48]         294,912\n",
            "      BatchNorm2d-28          [-1, 256, 48, 48]             512\n",
            "             ReLU-29          [-1, 256, 48, 48]               0\n",
            "           Conv2d-30          [-1, 256, 48, 48]         589,824\n",
            "    ResDoubleConv-31          [-1, 256, 48, 48]               0\n",
            "        MaxPool2d-32          [-1, 256, 24, 24]               0\n",
            "     ResDownBlock-33  [[-1, 256, 24, 24], [-1, 256, 48, 48]]               0\n",
            "           Conv2d-34          [-1, 512, 24, 24]         131,072\n",
            "      BatchNorm2d-35          [-1, 512, 24, 24]           1,024\n",
            "      BatchNorm2d-36          [-1, 256, 24, 24]             512\n",
            "             ReLU-37          [-1, 256, 24, 24]               0\n",
            "           Conv2d-38          [-1, 512, 24, 24]       1,179,648\n",
            "      BatchNorm2d-39          [-1, 512, 24, 24]           1,024\n",
            "             ReLU-40          [-1, 512, 24, 24]               0\n",
            "           Conv2d-41          [-1, 512, 24, 24]       2,359,296\n",
            "    ResDoubleConv-42          [-1, 512, 24, 24]               0\n",
            "        MaxPool2d-43          [-1, 512, 12, 12]               0\n",
            "     ResDownBlock-44  [[-1, 512, 12, 12], [-1, 512, 24, 24]]               0\n",
            "      BatchNorm2d-45          [-1, 512, 12, 12]           1,024\n",
            "             ReLU-46          [-1, 512, 12, 12]               0\n",
            "           Conv2d-47          [-1, 512, 12, 12]       2,359,296\n",
            "      BatchNorm2d-48          [-1, 512, 12, 12]           1,024\n",
            "             ReLU-49          [-1, 512, 12, 12]               0\n",
            "           Conv2d-50          [-1, 512, 12, 12]       2,359,296\n",
            "    ResDoubleConv-51          [-1, 512, 12, 12]               0\n",
            "================================================================\n",
            "Total params: 9,582,988\n",
            "Trainable params: 9,582,988\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.84\n",
            "Forward/backward pass size (MB): 14100212.25\n",
            "Params size (MB): 36.56\n",
            "Estimated Total Size (MB): 14100249.65\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mljk_p522IEB",
        "colab_type": "text"
      },
      "source": [
        "# Custom UNet - ResNeXt Backbone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nBRycl_KkEr",
        "colab_type": "text"
      },
      "source": [
        "The only change is the DoubleConv Backbone, everything else remains the same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGkbRlE_Xdua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResDoubleConv(nn.Module):\n",
        "    '''Basic DoubleConv of a ResNeXt'''\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResDoubleConv, self).__init__()\n",
        "\n",
        "        cardinality = 32\n",
        "\n",
        "        widen_factor = 6\n",
        "        base_width = 64\n",
        "\n",
        "        width_ratio = out_channels / (widen_factor * 64.)\n",
        "        D = cardinality * int(base_width * width_ratio)\n",
        "\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, D, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(D),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(D, D, kernel_size=3, padding=1, groups=cardinality, bias=False),\n",
        "            nn.BatchNorm2d(D),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(D, out_channels, kernel_size=1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.double_conv(x)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIEQ6zTzJI9R",
        "colab_type": "code",
        "outputId": "514cadf4-cc57-43d6-f9f7-82c2a67e521c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "summary(ResDoubleConv(512, 1024).to(device), (512, 12, 12))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "       BatchNorm2d-1          [-1, 512, 12, 12]           1,024\n",
            "              ReLU-2          [-1, 512, 12, 12]               0\n",
            "            Conv2d-3         [-1, 5440, 12, 12]       2,785,280\n",
            "       BatchNorm2d-4         [-1, 5440, 12, 12]          10,880\n",
            "              ReLU-5         [-1, 5440, 12, 12]               0\n",
            "            Conv2d-6         [-1, 5440, 12, 12]       8,323,200\n",
            "       BatchNorm2d-7         [-1, 5440, 12, 12]          10,880\n",
            "              ReLU-8         [-1, 5440, 12, 12]               0\n",
            "            Conv2d-9         [-1, 1024, 12, 12]       5,570,560\n",
            "================================================================\n",
            "Total params: 16,701,824\n",
            "Trainable params: 16,701,824\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.28\n",
            "Forward/backward pass size (MB): 38.11\n",
            "Params size (MB): 63.71\n",
            "Estimated Total Size (MB): 102.10\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X14IzW7-LQ_f",
        "colab": {}
      },
      "source": [
        "model = ResUNet().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9a95592c-537c-45a2-f4c8-d6a4373ca4eb",
        "id": "8aB1jAFiLQ_q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "summary(model, (6, 192, 192))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 192, 192]             384\n",
            "       BatchNorm2d-2         [-1, 64, 192, 192]             128\n",
            "       BatchNorm2d-3          [-1, 6, 192, 192]              12\n",
            "              ReLU-4          [-1, 6, 192, 192]               0\n",
            "            Conv2d-5        [-1, 320, 192, 192]           1,920\n",
            "       BatchNorm2d-6        [-1, 320, 192, 192]             640\n",
            "              ReLU-7        [-1, 320, 192, 192]               0\n",
            "            Conv2d-8        [-1, 320, 192, 192]          28,800\n",
            "       BatchNorm2d-9        [-1, 320, 192, 192]             640\n",
            "             ReLU-10        [-1, 320, 192, 192]               0\n",
            "           Conv2d-11         [-1, 64, 192, 192]          20,480\n",
            "    ResDoubleConv-12         [-1, 64, 192, 192]               0\n",
            "        MaxPool2d-13           [-1, 64, 96, 96]               0\n",
            "     ResDownBlock-14  [[-1, 64, 96, 96], [-1, 64, 192, 192]]               0\n",
            "           Conv2d-15          [-1, 128, 96, 96]           8,192\n",
            "      BatchNorm2d-16          [-1, 128, 96, 96]             256\n",
            "      BatchNorm2d-17           [-1, 64, 96, 96]             128\n",
            "             ReLU-18           [-1, 64, 96, 96]               0\n",
            "           Conv2d-19          [-1, 672, 96, 96]          43,008\n",
            "      BatchNorm2d-20          [-1, 672, 96, 96]           1,344\n",
            "             ReLU-21          [-1, 672, 96, 96]               0\n",
            "           Conv2d-22          [-1, 672, 96, 96]         127,008\n",
            "      BatchNorm2d-23          [-1, 672, 96, 96]           1,344\n",
            "             ReLU-24          [-1, 672, 96, 96]               0\n",
            "           Conv2d-25          [-1, 128, 96, 96]          86,016\n",
            "    ResDoubleConv-26          [-1, 128, 96, 96]               0\n",
            "        MaxPool2d-27          [-1, 128, 48, 48]               0\n",
            "     ResDownBlock-28  [[-1, 128, 48, 48], [-1, 128, 96, 96]]               0\n",
            "           Conv2d-29          [-1, 256, 48, 48]          32,768\n",
            "      BatchNorm2d-30          [-1, 256, 48, 48]             512\n",
            "      BatchNorm2d-31          [-1, 128, 48, 48]             256\n",
            "             ReLU-32          [-1, 128, 48, 48]               0\n",
            "           Conv2d-33         [-1, 1344, 48, 48]         172,032\n",
            "      BatchNorm2d-34         [-1, 1344, 48, 48]           2,688\n",
            "             ReLU-35         [-1, 1344, 48, 48]               0\n",
            "           Conv2d-36         [-1, 1344, 48, 48]         508,032\n",
            "      BatchNorm2d-37         [-1, 1344, 48, 48]           2,688\n",
            "             ReLU-38         [-1, 1344, 48, 48]               0\n",
            "           Conv2d-39          [-1, 256, 48, 48]         344,064\n",
            "    ResDoubleConv-40          [-1, 256, 48, 48]               0\n",
            "        MaxPool2d-41          [-1, 256, 24, 24]               0\n",
            "     ResDownBlock-42  [[-1, 256, 24, 24], [-1, 256, 48, 48]]               0\n",
            "           Conv2d-43          [-1, 512, 24, 24]         131,072\n",
            "      BatchNorm2d-44          [-1, 512, 24, 24]           1,024\n",
            "      BatchNorm2d-45          [-1, 256, 24, 24]             512\n",
            "             ReLU-46          [-1, 256, 24, 24]               0\n",
            "           Conv2d-47         [-1, 2720, 24, 24]         696,320\n",
            "      BatchNorm2d-48         [-1, 2720, 24, 24]           5,440\n",
            "             ReLU-49         [-1, 2720, 24, 24]               0\n",
            "           Conv2d-50         [-1, 2720, 24, 24]       2,080,800\n",
            "      BatchNorm2d-51         [-1, 2720, 24, 24]           5,440\n",
            "             ReLU-52         [-1, 2720, 24, 24]               0\n",
            "           Conv2d-53          [-1, 512, 24, 24]       1,392,640\n",
            "    ResDoubleConv-54          [-1, 512, 24, 24]               0\n",
            "        MaxPool2d-55          [-1, 512, 12, 12]               0\n",
            "     ResDownBlock-56  [[-1, 512, 12, 12], [-1, 512, 24, 24]]               0\n",
            "      BatchNorm2d-57          [-1, 512, 12, 12]           1,024\n",
            "             ReLU-58          [-1, 512, 12, 12]               0\n",
            "           Conv2d-59         [-1, 2720, 12, 12]       1,392,640\n",
            "      BatchNorm2d-60         [-1, 2720, 12, 12]           5,440\n",
            "             ReLU-61         [-1, 2720, 12, 12]               0\n",
            "           Conv2d-62         [-1, 2720, 12, 12]       2,080,800\n",
            "      BatchNorm2d-63         [-1, 2720, 12, 12]           5,440\n",
            "             ReLU-64         [-1, 2720, 12, 12]               0\n",
            "           Conv2d-65          [-1, 512, 12, 12]       1,392,640\n",
            "    ResDoubleConv-66          [-1, 512, 12, 12]               0\n",
            "     PixelShuffle-67          [-1, 128, 24, 24]               0\n",
            "     PixelShuffle-68          [-1, 128, 24, 24]               0\n",
            "     PixelShuffle-69          [-1, 128, 24, 24]               0\n",
            "     PixelShuffle-70          [-1, 128, 24, 24]               0\n",
            "           Conv2d-71          [-1, 512, 24, 24]         524,288\n",
            "      BatchNorm2d-72          [-1, 512, 24, 24]           1,024\n",
            "      BatchNorm2d-73         [-1, 1024, 24, 24]           2,048\n",
            "             ReLU-74         [-1, 1024, 24, 24]               0\n",
            "           Conv2d-75         [-1, 2720, 24, 24]       2,785,280\n",
            "      BatchNorm2d-76         [-1, 2720, 24, 24]           5,440\n",
            "             ReLU-77         [-1, 2720, 24, 24]               0\n",
            "           Conv2d-78         [-1, 2720, 24, 24]       2,080,800\n",
            "      BatchNorm2d-79         [-1, 2720, 24, 24]           5,440\n",
            "             ReLU-80         [-1, 2720, 24, 24]               0\n",
            "           Conv2d-81          [-1, 512, 24, 24]       1,392,640\n",
            "    ResDoubleConv-82          [-1, 512, 24, 24]               0\n",
            "       ResUpBlock-83          [-1, 512, 24, 24]               0\n",
            "     PixelShuffle-84          [-1, 128, 48, 48]               0\n",
            "     PixelShuffle-85          [-1, 128, 48, 48]               0\n",
            "     PixelShuffle-86          [-1, 128, 48, 48]               0\n",
            "     PixelShuffle-87          [-1, 128, 48, 48]               0\n",
            "           Conv2d-88          [-1, 256, 48, 48]         196,608\n",
            "      BatchNorm2d-89          [-1, 256, 48, 48]             512\n",
            "      BatchNorm2d-90          [-1, 768, 48, 48]           1,536\n",
            "             ReLU-91          [-1, 768, 48, 48]               0\n",
            "           Conv2d-92         [-1, 1344, 48, 48]       1,032,192\n",
            "      BatchNorm2d-93         [-1, 1344, 48, 48]           2,688\n",
            "             ReLU-94         [-1, 1344, 48, 48]               0\n",
            "           Conv2d-95         [-1, 1344, 48, 48]         508,032\n",
            "      BatchNorm2d-96         [-1, 1344, 48, 48]           2,688\n",
            "             ReLU-97         [-1, 1344, 48, 48]               0\n",
            "           Conv2d-98          [-1, 256, 48, 48]         344,064\n",
            "    ResDoubleConv-99          [-1, 256, 48, 48]               0\n",
            "      ResUpBlock-100          [-1, 256, 48, 48]               0\n",
            "    PixelShuffle-101           [-1, 64, 96, 96]               0\n",
            "    PixelShuffle-102           [-1, 64, 96, 96]               0\n",
            "    PixelShuffle-103           [-1, 64, 96, 96]               0\n",
            "    PixelShuffle-104           [-1, 64, 96, 96]               0\n",
            "          Conv2d-105          [-1, 128, 96, 96]          49,152\n",
            "     BatchNorm2d-106          [-1, 128, 96, 96]             256\n",
            "     BatchNorm2d-107          [-1, 384, 96, 96]             768\n",
            "            ReLU-108          [-1, 384, 96, 96]               0\n",
            "          Conv2d-109          [-1, 672, 96, 96]         258,048\n",
            "     BatchNorm2d-110          [-1, 672, 96, 96]           1,344\n",
            "            ReLU-111          [-1, 672, 96, 96]               0\n",
            "          Conv2d-112          [-1, 672, 96, 96]         127,008\n",
            "     BatchNorm2d-113          [-1, 672, 96, 96]           1,344\n",
            "            ReLU-114          [-1, 672, 96, 96]               0\n",
            "          Conv2d-115          [-1, 128, 96, 96]          86,016\n",
            "   ResDoubleConv-116          [-1, 128, 96, 96]               0\n",
            "      ResUpBlock-117          [-1, 128, 96, 96]               0\n",
            "    PixelShuffle-118         [-1, 32, 192, 192]               0\n",
            "    PixelShuffle-119         [-1, 32, 192, 192]               0\n",
            "    PixelShuffle-120         [-1, 32, 192, 192]               0\n",
            "    PixelShuffle-121         [-1, 32, 192, 192]               0\n",
            "          Conv2d-122         [-1, 64, 192, 192]          12,288\n",
            "     BatchNorm2d-123         [-1, 64, 192, 192]             128\n",
            "     BatchNorm2d-124        [-1, 192, 192, 192]             384\n",
            "            ReLU-125        [-1, 192, 192, 192]               0\n",
            "          Conv2d-126        [-1, 320, 192, 192]          61,440\n",
            "     BatchNorm2d-127        [-1, 320, 192, 192]             640\n",
            "            ReLU-128        [-1, 320, 192, 192]               0\n",
            "          Conv2d-129        [-1, 320, 192, 192]          28,800\n",
            "     BatchNorm2d-130        [-1, 320, 192, 192]             640\n",
            "            ReLU-131        [-1, 320, 192, 192]               0\n",
            "          Conv2d-132         [-1, 64, 192, 192]          20,480\n",
            "   ResDoubleConv-133         [-1, 64, 192, 192]               0\n",
            "      ResUpBlock-134         [-1, 64, 192, 192]               0\n",
            "          Conv2d-135          [-1, 1, 192, 192]              64\n",
            "    PixelShuffle-136          [-1, 128, 24, 24]               0\n",
            "    PixelShuffle-137          [-1, 128, 24, 24]               0\n",
            "    PixelShuffle-138          [-1, 128, 24, 24]               0\n",
            "    PixelShuffle-139          [-1, 128, 24, 24]               0\n",
            "          Conv2d-140          [-1, 512, 24, 24]         786,432\n",
            "     BatchNorm2d-141          [-1, 512, 24, 24]           1,024\n",
            "     BatchNorm2d-142         [-1, 1536, 24, 24]           3,072\n",
            "            ReLU-143         [-1, 1536, 24, 24]               0\n",
            "          Conv2d-144         [-1, 2720, 24, 24]       4,177,920\n",
            "     BatchNorm2d-145         [-1, 2720, 24, 24]           5,440\n",
            "            ReLU-146         [-1, 2720, 24, 24]               0\n",
            "          Conv2d-147         [-1, 2720, 24, 24]       2,080,800\n",
            "     BatchNorm2d-148         [-1, 2720, 24, 24]           5,440\n",
            "            ReLU-149         [-1, 2720, 24, 24]               0\n",
            "          Conv2d-150          [-1, 512, 24, 24]       1,392,640\n",
            "   ResDoubleConv-151          [-1, 512, 24, 24]               0\n",
            "      ResUpBlock-152          [-1, 512, 24, 24]               0\n",
            "    PixelShuffle-153          [-1, 128, 48, 48]               0\n",
            "    PixelShuffle-154          [-1, 128, 48, 48]               0\n",
            "    PixelShuffle-155          [-1, 128, 48, 48]               0\n",
            "    PixelShuffle-156          [-1, 128, 48, 48]               0\n",
            "          Conv2d-157          [-1, 256, 48, 48]         262,144\n",
            "     BatchNorm2d-158          [-1, 256, 48, 48]             512\n",
            "     BatchNorm2d-159         [-1, 1024, 48, 48]           2,048\n",
            "            ReLU-160         [-1, 1024, 48, 48]               0\n",
            "          Conv2d-161         [-1, 1344, 48, 48]       1,376,256\n",
            "     BatchNorm2d-162         [-1, 1344, 48, 48]           2,688\n",
            "            ReLU-163         [-1, 1344, 48, 48]               0\n",
            "          Conv2d-164         [-1, 1344, 48, 48]         508,032\n",
            "     BatchNorm2d-165         [-1, 1344, 48, 48]           2,688\n",
            "            ReLU-166         [-1, 1344, 48, 48]               0\n",
            "          Conv2d-167          [-1, 256, 48, 48]         344,064\n",
            "   ResDoubleConv-168          [-1, 256, 48, 48]               0\n",
            "      ResUpBlock-169          [-1, 256, 48, 48]               0\n",
            "    PixelShuffle-170           [-1, 64, 96, 96]               0\n",
            "    PixelShuffle-171           [-1, 64, 96, 96]               0\n",
            "    PixelShuffle-172           [-1, 64, 96, 96]               0\n",
            "    PixelShuffle-173           [-1, 64, 96, 96]               0\n",
            "          Conv2d-174          [-1, 128, 96, 96]          65,536\n",
            "     BatchNorm2d-175          [-1, 128, 96, 96]             256\n",
            "     BatchNorm2d-176          [-1, 512, 96, 96]           1,024\n",
            "            ReLU-177          [-1, 512, 96, 96]               0\n",
            "          Conv2d-178          [-1, 672, 96, 96]         344,064\n",
            "     BatchNorm2d-179          [-1, 672, 96, 96]           1,344\n",
            "            ReLU-180          [-1, 672, 96, 96]               0\n",
            "          Conv2d-181          [-1, 672, 96, 96]         127,008\n",
            "     BatchNorm2d-182          [-1, 672, 96, 96]           1,344\n",
            "            ReLU-183          [-1, 672, 96, 96]               0\n",
            "          Conv2d-184          [-1, 128, 96, 96]          86,016\n",
            "   ResDoubleConv-185          [-1, 128, 96, 96]               0\n",
            "      ResUpBlock-186          [-1, 128, 96, 96]               0\n",
            "    PixelShuffle-187         [-1, 32, 192, 192]               0\n",
            "    PixelShuffle-188         [-1, 32, 192, 192]               0\n",
            "    PixelShuffle-189         [-1, 32, 192, 192]               0\n",
            "    PixelShuffle-190         [-1, 32, 192, 192]               0\n",
            "          Conv2d-191         [-1, 64, 192, 192]          16,384\n",
            "     BatchNorm2d-192         [-1, 64, 192, 192]             128\n",
            "     BatchNorm2d-193        [-1, 256, 192, 192]             512\n",
            "            ReLU-194        [-1, 256, 192, 192]               0\n",
            "          Conv2d-195        [-1, 320, 192, 192]          81,920\n",
            "     BatchNorm2d-196        [-1, 320, 192, 192]             640\n",
            "            ReLU-197        [-1, 320, 192, 192]               0\n",
            "          Conv2d-198        [-1, 320, 192, 192]          28,800\n",
            "     BatchNorm2d-199        [-1, 320, 192, 192]             640\n",
            "            ReLU-200        [-1, 320, 192, 192]               0\n",
            "          Conv2d-201         [-1, 64, 192, 192]          20,480\n",
            "   ResDoubleConv-202         [-1, 64, 192, 192]               0\n",
            "      ResUpBlock-203         [-1, 64, 192, 192]               0\n",
            "          Conv2d-204          [-1, 1, 192, 192]              64\n",
            "================================================================\n",
            "Total params: 31,836,012\n",
            "Trainable params: 31,836,012\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.84\n",
            "Forward/backward pass size (MB): 14096254.29\n",
            "Params size (MB): 121.44\n",
            "Estimated Total Size (MB): 14096376.58\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COZ_qjaOLTpm",
        "colab_type": "code",
        "outputId": "50b15177-455e-4fdc-914e-5453f0254876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348,
          "referenced_widgets": [
            "9f314f899dc84aa993eada03b0e42571",
            "b4a107cd2d874413bb430bce4c61d856",
            "b4b72decdee14c38b056499138511151",
            "b445416362c140aaa536d41b59f0a6a0",
            "ab6c33f78dcc44d198d2c4e273cf543f",
            "85a55a0e00ca4813976dbff5d9fcc508",
            "08ad2f6aa44746af945e434172841b93",
            "99aca92e6e5a47908cacaed3286b4271"
          ]
        }
      },
      "source": [
        "model = ResUNet()\n",
        "model.to(device)\n",
        "for i in tqdm(range(6250)):\n",
        "    input = torch.randn(64, 6, 96, 96)\n",
        "    input = input.to(device)\n",
        "    model(input)\n",
        "\n",
        "    del input\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f314f899dc84aa993eada03b0e42571",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=6250.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-85dd9825114e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDbRO7loQbou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0mWkqrpPTlQ",
        "colab_type": "code",
        "outputId": "24963e5c-1d6a-4e6e-f3d8-7d5ab2e22232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.memory_allocated()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTIrvF3FG42t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "def convrelu(in_channels, out_channels, kernel, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "\n",
        "class ResNetUNet(nn.Module):\n",
        "    def __init__(self, n_class):\n",
        "        super().__init__()\n",
        "\n",
        "        self.base_model = models.resnet18(pretrained=True)\n",
        "        self.base_layers = list(self.base_model.children())\n",
        "\n",
        "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
        "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
        "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n",
        "        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
        "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n",
        "        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
        "        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n",
        "        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
        "        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
        "        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
        "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
        "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
        "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
        "\n",
        "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
        "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
        "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
        "\n",
        "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x_original = self.conv_original_size0(input)\n",
        "        x_original = self.conv_original_size1(x_original)\n",
        "\n",
        "        layer0 = self.layer0(input)\n",
        "        layer1 = self.layer1(layer0)\n",
        "        layer2 = self.layer2(layer1)\n",
        "        layer3 = self.layer3(layer2)\n",
        "        layer4 = self.layer4(layer3)\n",
        "\n",
        "        layer4 = self.layer4_1x1(layer4)\n",
        "        x = self.upsample(layer4)\n",
        "        layer3 = self.layer3_1x1(layer3)\n",
        "        x = torch.cat([x, layer3], dim=1)\n",
        "        x = self.conv_up3(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer2 = self.layer2_1x1(layer2)\n",
        "        x = torch.cat([x, layer2], dim=1)\n",
        "        x = self.conv_up2(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer1 = self.layer1_1x1(layer1)\n",
        "        x = torch.cat([x, layer1], dim=1)\n",
        "        x = self.conv_up1(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer0 = self.layer0_1x1(layer0)\n",
        "        x = torch.cat([x, layer0], dim=1)\n",
        "        x = self.conv_up0(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, x_original], dim=1)\n",
        "        x = self.conv_original_size2(x)\n",
        "\n",
        "        out = self.conv_last(x)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRWiCwRnG5N5",
        "colab_type": "code",
        "outputId": "f4f6bcd5-3ca1-4fa0-a96d-c6fc0a34d63d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4e836802abf842ec8f09f7840e5523a8",
            "e8c557c5d4b34558b82a7a65c495b371",
            "d14b91c924064e19ad99baf90aaa8912",
            "e45f5706eb594834b7e449f20272c48e",
            "aed8d19fc841452d9a5f58fbb45c75d9",
            "518c152f51d7433fb8b62eebc0ab2b8d",
            "4e9b313612e14c1ab0412877b167e86c",
            "a114baf9297b46c9b76b8efa4aa21031"
          ]
        }
      },
      "source": [
        "summary(ResNetUNet(10).to(device), (3, 192, 192))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e836802abf842ec8f09f7840e5523a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 192, 192]           1,792\n",
            "              ReLU-2         [-1, 64, 192, 192]               0\n",
            "            Conv2d-3         [-1, 64, 192, 192]          36,928\n",
            "              ReLU-4         [-1, 64, 192, 192]               0\n",
            "            Conv2d-5           [-1, 64, 96, 96]           9,408\n",
            "            Conv2d-6           [-1, 64, 96, 96]           9,408\n",
            "       BatchNorm2d-7           [-1, 64, 96, 96]             128\n",
            "       BatchNorm2d-8           [-1, 64, 96, 96]             128\n",
            "              ReLU-9           [-1, 64, 96, 96]               0\n",
            "             ReLU-10           [-1, 64, 96, 96]               0\n",
            "        MaxPool2d-11           [-1, 64, 48, 48]               0\n",
            "        MaxPool2d-12           [-1, 64, 48, 48]               0\n",
            "           Conv2d-13           [-1, 64, 48, 48]          36,864\n",
            "           Conv2d-14           [-1, 64, 48, 48]          36,864\n",
            "      BatchNorm2d-15           [-1, 64, 48, 48]             128\n",
            "      BatchNorm2d-16           [-1, 64, 48, 48]             128\n",
            "             ReLU-17           [-1, 64, 48, 48]               0\n",
            "             ReLU-18           [-1, 64, 48, 48]               0\n",
            "           Conv2d-19           [-1, 64, 48, 48]          36,864\n",
            "           Conv2d-20           [-1, 64, 48, 48]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 48, 48]             128\n",
            "      BatchNorm2d-22           [-1, 64, 48, 48]             128\n",
            "             ReLU-23           [-1, 64, 48, 48]               0\n",
            "             ReLU-24           [-1, 64, 48, 48]               0\n",
            "       BasicBlock-25           [-1, 64, 48, 48]               0\n",
            "       BasicBlock-26           [-1, 64, 48, 48]               0\n",
            "           Conv2d-27           [-1, 64, 48, 48]          36,864\n",
            "           Conv2d-28           [-1, 64, 48, 48]          36,864\n",
            "      BatchNorm2d-29           [-1, 64, 48, 48]             128\n",
            "      BatchNorm2d-30           [-1, 64, 48, 48]             128\n",
            "             ReLU-31           [-1, 64, 48, 48]               0\n",
            "             ReLU-32           [-1, 64, 48, 48]               0\n",
            "           Conv2d-33           [-1, 64, 48, 48]          36,864\n",
            "           Conv2d-34           [-1, 64, 48, 48]          36,864\n",
            "      BatchNorm2d-35           [-1, 64, 48, 48]             128\n",
            "      BatchNorm2d-36           [-1, 64, 48, 48]             128\n",
            "             ReLU-37           [-1, 64, 48, 48]               0\n",
            "             ReLU-38           [-1, 64, 48, 48]               0\n",
            "       BasicBlock-39           [-1, 64, 48, 48]               0\n",
            "       BasicBlock-40           [-1, 64, 48, 48]               0\n",
            "           Conv2d-41          [-1, 128, 24, 24]          73,728\n",
            "           Conv2d-42          [-1, 128, 24, 24]          73,728\n",
            "      BatchNorm2d-43          [-1, 128, 24, 24]             256\n",
            "      BatchNorm2d-44          [-1, 128, 24, 24]             256\n",
            "             ReLU-45          [-1, 128, 24, 24]               0\n",
            "             ReLU-46          [-1, 128, 24, 24]               0\n",
            "           Conv2d-47          [-1, 128, 24, 24]         147,456\n",
            "           Conv2d-48          [-1, 128, 24, 24]         147,456\n",
            "      BatchNorm2d-49          [-1, 128, 24, 24]             256\n",
            "      BatchNorm2d-50          [-1, 128, 24, 24]             256\n",
            "           Conv2d-51          [-1, 128, 24, 24]           8,192\n",
            "           Conv2d-52          [-1, 128, 24, 24]           8,192\n",
            "      BatchNorm2d-53          [-1, 128, 24, 24]             256\n",
            "      BatchNorm2d-54          [-1, 128, 24, 24]             256\n",
            "             ReLU-55          [-1, 128, 24, 24]               0\n",
            "             ReLU-56          [-1, 128, 24, 24]               0\n",
            "       BasicBlock-57          [-1, 128, 24, 24]               0\n",
            "       BasicBlock-58          [-1, 128, 24, 24]               0\n",
            "           Conv2d-59          [-1, 128, 24, 24]         147,456\n",
            "           Conv2d-60          [-1, 128, 24, 24]         147,456\n",
            "      BatchNorm2d-61          [-1, 128, 24, 24]             256\n",
            "      BatchNorm2d-62          [-1, 128, 24, 24]             256\n",
            "             ReLU-63          [-1, 128, 24, 24]               0\n",
            "             ReLU-64          [-1, 128, 24, 24]               0\n",
            "           Conv2d-65          [-1, 128, 24, 24]         147,456\n",
            "           Conv2d-66          [-1, 128, 24, 24]         147,456\n",
            "      BatchNorm2d-67          [-1, 128, 24, 24]             256\n",
            "      BatchNorm2d-68          [-1, 128, 24, 24]             256\n",
            "             ReLU-69          [-1, 128, 24, 24]               0\n",
            "             ReLU-70          [-1, 128, 24, 24]               0\n",
            "       BasicBlock-71          [-1, 128, 24, 24]               0\n",
            "       BasicBlock-72          [-1, 128, 24, 24]               0\n",
            "           Conv2d-73          [-1, 256, 12, 12]         294,912\n",
            "           Conv2d-74          [-1, 256, 12, 12]         294,912\n",
            "      BatchNorm2d-75          [-1, 256, 12, 12]             512\n",
            "      BatchNorm2d-76          [-1, 256, 12, 12]             512\n",
            "             ReLU-77          [-1, 256, 12, 12]               0\n",
            "             ReLU-78          [-1, 256, 12, 12]               0\n",
            "           Conv2d-79          [-1, 256, 12, 12]         589,824\n",
            "           Conv2d-80          [-1, 256, 12, 12]         589,824\n",
            "      BatchNorm2d-81          [-1, 256, 12, 12]             512\n",
            "      BatchNorm2d-82          [-1, 256, 12, 12]             512\n",
            "           Conv2d-83          [-1, 256, 12, 12]          32,768\n",
            "           Conv2d-84          [-1, 256, 12, 12]          32,768\n",
            "      BatchNorm2d-85          [-1, 256, 12, 12]             512\n",
            "      BatchNorm2d-86          [-1, 256, 12, 12]             512\n",
            "             ReLU-87          [-1, 256, 12, 12]               0\n",
            "             ReLU-88          [-1, 256, 12, 12]               0\n",
            "       BasicBlock-89          [-1, 256, 12, 12]               0\n",
            "       BasicBlock-90          [-1, 256, 12, 12]               0\n",
            "           Conv2d-91          [-1, 256, 12, 12]         589,824\n",
            "           Conv2d-92          [-1, 256, 12, 12]         589,824\n",
            "      BatchNorm2d-93          [-1, 256, 12, 12]             512\n",
            "      BatchNorm2d-94          [-1, 256, 12, 12]             512\n",
            "             ReLU-95          [-1, 256, 12, 12]               0\n",
            "             ReLU-96          [-1, 256, 12, 12]               0\n",
            "           Conv2d-97          [-1, 256, 12, 12]         589,824\n",
            "           Conv2d-98          [-1, 256, 12, 12]         589,824\n",
            "      BatchNorm2d-99          [-1, 256, 12, 12]             512\n",
            "     BatchNorm2d-100          [-1, 256, 12, 12]             512\n",
            "            ReLU-101          [-1, 256, 12, 12]               0\n",
            "            ReLU-102          [-1, 256, 12, 12]               0\n",
            "      BasicBlock-103          [-1, 256, 12, 12]               0\n",
            "      BasicBlock-104          [-1, 256, 12, 12]               0\n",
            "          Conv2d-105            [-1, 512, 6, 6]       1,179,648\n",
            "          Conv2d-106            [-1, 512, 6, 6]       1,179,648\n",
            "     BatchNorm2d-107            [-1, 512, 6, 6]           1,024\n",
            "     BatchNorm2d-108            [-1, 512, 6, 6]           1,024\n",
            "            ReLU-109            [-1, 512, 6, 6]               0\n",
            "            ReLU-110            [-1, 512, 6, 6]               0\n",
            "          Conv2d-111            [-1, 512, 6, 6]       2,359,296\n",
            "          Conv2d-112            [-1, 512, 6, 6]       2,359,296\n",
            "     BatchNorm2d-113            [-1, 512, 6, 6]           1,024\n",
            "     BatchNorm2d-114            [-1, 512, 6, 6]           1,024\n",
            "          Conv2d-115            [-1, 512, 6, 6]         131,072\n",
            "          Conv2d-116            [-1, 512, 6, 6]         131,072\n",
            "     BatchNorm2d-117            [-1, 512, 6, 6]           1,024\n",
            "     BatchNorm2d-118            [-1, 512, 6, 6]           1,024\n",
            "            ReLU-119            [-1, 512, 6, 6]               0\n",
            "            ReLU-120            [-1, 512, 6, 6]               0\n",
            "      BasicBlock-121            [-1, 512, 6, 6]               0\n",
            "      BasicBlock-122            [-1, 512, 6, 6]               0\n",
            "          Conv2d-123            [-1, 512, 6, 6]       2,359,296\n",
            "          Conv2d-124            [-1, 512, 6, 6]       2,359,296\n",
            "     BatchNorm2d-125            [-1, 512, 6, 6]           1,024\n",
            "     BatchNorm2d-126            [-1, 512, 6, 6]           1,024\n",
            "            ReLU-127            [-1, 512, 6, 6]               0\n",
            "            ReLU-128            [-1, 512, 6, 6]               0\n",
            "          Conv2d-129            [-1, 512, 6, 6]       2,359,296\n",
            "          Conv2d-130            [-1, 512, 6, 6]       2,359,296\n",
            "     BatchNorm2d-131            [-1, 512, 6, 6]           1,024\n",
            "     BatchNorm2d-132            [-1, 512, 6, 6]           1,024\n",
            "            ReLU-133            [-1, 512, 6, 6]               0\n",
            "            ReLU-134            [-1, 512, 6, 6]               0\n",
            "      BasicBlock-135            [-1, 512, 6, 6]               0\n",
            "      BasicBlock-136            [-1, 512, 6, 6]               0\n",
            "          Conv2d-137            [-1, 512, 6, 6]         262,656\n",
            "            ReLU-138            [-1, 512, 6, 6]               0\n",
            "        Upsample-139          [-1, 512, 12, 12]               0\n",
            "          Conv2d-140          [-1, 256, 12, 12]          65,792\n",
            "            ReLU-141          [-1, 256, 12, 12]               0\n",
            "          Conv2d-142          [-1, 512, 12, 12]       3,539,456\n",
            "            ReLU-143          [-1, 512, 12, 12]               0\n",
            "        Upsample-144          [-1, 512, 24, 24]               0\n",
            "          Conv2d-145          [-1, 128, 24, 24]          16,512\n",
            "            ReLU-146          [-1, 128, 24, 24]               0\n",
            "          Conv2d-147          [-1, 256, 24, 24]       1,474,816\n",
            "            ReLU-148          [-1, 256, 24, 24]               0\n",
            "        Upsample-149          [-1, 256, 48, 48]               0\n",
            "          Conv2d-150           [-1, 64, 48, 48]           4,160\n",
            "            ReLU-151           [-1, 64, 48, 48]               0\n",
            "          Conv2d-152          [-1, 256, 48, 48]         737,536\n",
            "            ReLU-153          [-1, 256, 48, 48]               0\n",
            "        Upsample-154          [-1, 256, 96, 96]               0\n",
            "          Conv2d-155           [-1, 64, 96, 96]           4,160\n",
            "            ReLU-156           [-1, 64, 96, 96]               0\n",
            "          Conv2d-157          [-1, 128, 96, 96]         368,768\n",
            "            ReLU-158          [-1, 128, 96, 96]               0\n",
            "        Upsample-159        [-1, 128, 192, 192]               0\n",
            "          Conv2d-160         [-1, 64, 192, 192]         110,656\n",
            "            ReLU-161         [-1, 64, 192, 192]               0\n",
            "          Conv2d-162         [-1, 10, 192, 192]             650\n",
            "================================================================\n",
            "Total params: 18,313,394\n",
            "Trainable params: 18,313,394\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.42\n",
            "Forward/backward pass size (MB): 307.97\n",
            "Params size (MB): 69.86\n",
            "Estimated Total Size (MB): 378.25\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KQl8ZmCHDHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import importlib\n",
        "\n",
        "\n",
        "class conv(nn.Module):\n",
        "    def __init__(self, num_in_layers, num_out_layers, kernel_size, stride):\n",
        "        super(conv, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.conv_base = nn.Conv2d(num_in_layers, num_out_layers, kernel_size=kernel_size, stride=stride)\n",
        "        self.normalize = nn.BatchNorm2d(num_out_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        p = int(np.floor((self.kernel_size-1)/2))\n",
        "        p2d = (p, p, p, p)\n",
        "        x = self.conv_base(F.pad(x, p2d))\n",
        "        x = self.normalize(x)\n",
        "        return F.elu(x, inplace=True)\n",
        "\n",
        "\n",
        "class convblock(nn.Module):\n",
        "    def __init__(self, num_in_layers, num_out_layers, kernel_size):\n",
        "        super(convblock, self).__init__()\n",
        "        self.conv1 = conv(num_in_layers, num_out_layers, kernel_size, 1)\n",
        "        self.conv2 = conv(num_out_layers, num_out_layers, kernel_size, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        return self.conv2(x)\n",
        "\n",
        "\n",
        "class maxpool(nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super(maxpool, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        p = int(np.floor((self.kernel_size-1) / 2))\n",
        "        p2d = (p, p, p, p)\n",
        "        return F.max_pool2d(F.pad(x, p2d), self.kernel_size, stride=2)\n",
        "\n",
        "\n",
        "class resconv(nn.Module):\n",
        "    def __init__(self, num_in_layers, num_out_layers, stride):\n",
        "        super(resconv, self).__init__()\n",
        "        self.num_out_layers = num_out_layers\n",
        "        self.stride = stride\n",
        "        self.conv1 = conv(num_in_layers, num_out_layers, 1, 1)\n",
        "        self.conv2 = conv(num_out_layers, num_out_layers, 3, stride)\n",
        "        self.conv3 = nn.Conv2d(num_out_layers, 4*num_out_layers, kernel_size=1, stride=1)\n",
        "        self.conv4 = nn.Conv2d(num_in_layers, 4*num_out_layers, kernel_size=1, stride=stride)\n",
        "        self.normalize = nn.BatchNorm2d(4*num_out_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # do_proj = x.size()[1] != self.num_out_layers or self.stride == 2\n",
        "        do_proj = True\n",
        "        shortcut = []\n",
        "        x_out = self.conv1(x)\n",
        "        x_out = self.conv2(x_out)\n",
        "        x_out = self.conv3(x_out)\n",
        "        if do_proj:\n",
        "            shortcut = self.conv4(x)\n",
        "        else:\n",
        "            shortcut = x\n",
        "        return F.elu(self.normalize(x_out + shortcut), inplace=True)\n",
        "\n",
        "\n",
        "class resconv_basic(nn.Module):\n",
        "    # for resnet18\n",
        "    def __init__(self, num_in_layers, num_out_layers, stride):\n",
        "        super(resconv_basic, self).__init__()\n",
        "        self.num_out_layers = num_out_layers\n",
        "        self.stride = stride\n",
        "        self.conv1 = conv(num_in_layers, num_out_layers, 3, stride)\n",
        "        self.conv2 = conv(num_out_layers, num_out_layers, 3, 1)\n",
        "        self.conv3 = nn.Conv2d(num_in_layers, num_out_layers, kernel_size=1, stride=stride)\n",
        "        self.normalize = nn.BatchNorm2d(num_out_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #         do_proj = x.size()[1] != self.num_out_layers or self.stride == 2\n",
        "        do_proj = True\n",
        "        shortcut = []\n",
        "        x_out = self.conv1(x)\n",
        "        x_out = self.conv2(x_out)\n",
        "        if do_proj:\n",
        "            shortcut = self.conv3(x)\n",
        "        else:\n",
        "            shortcut = x\n",
        "        return F.elu(self.normalize(x_out + shortcut), inplace=True)\n",
        "\n",
        "\n",
        "def resblock(num_in_layers, num_out_layers, num_blocks, stride):\n",
        "    layers = []\n",
        "    layers.append(resconv(num_in_layers, num_out_layers, stride))\n",
        "    for i in range(1, num_blocks - 1):\n",
        "        layers.append(resconv(4 * num_out_layers, num_out_layers, 1))\n",
        "    layers.append(resconv(4 * num_out_layers, num_out_layers, 1))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def resblock_basic(num_in_layers, num_out_layers, num_blocks, stride):\n",
        "    layers = []\n",
        "    layers.append(resconv_basic(num_in_layers, num_out_layers, stride))\n",
        "    for i in range(1, num_blocks):\n",
        "        layers.append(resconv_basic(num_out_layers, num_out_layers, 1))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class upconv(nn.Module):\n",
        "    def __init__(self, num_in_layers, num_out_layers, kernel_size, scale):\n",
        "        super(upconv, self).__init__()\n",
        "        self.scale = scale\n",
        "        self.conv1 = conv(num_in_layers, num_out_layers, kernel_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.interpolate(x, scale_factor=self.scale, mode='bilinear', align_corners=True)\n",
        "        return self.conv1(x)\n",
        "\n",
        "\n",
        "class get_disp(nn.Module):\n",
        "    def __init__(self, num_in_layers):\n",
        "        super(get_disp, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(num_in_layers, 2, kernel_size=3, stride=1)\n",
        "        self.normalize = nn.BatchNorm2d(2)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        p = 1\n",
        "        p2d = (p, p, p, p)\n",
        "        x = self.conv1(F.pad(x, p2d))\n",
        "        x = self.normalize(x)\n",
        "        return 0.3 * self.sigmoid(x)\n",
        "\n",
        "\n",
        "class Resnet50_md(nn.Module):\n",
        "    def __init__(self, num_in_layers):\n",
        "        super(Resnet50_md, self).__init__()\n",
        "        # encoder\n",
        "        self.conv1 = conv(num_in_layers, 64, 7, 2)  # H/2  -   64D\n",
        "        self.pool1 = maxpool(3)  # H/4  -   64D\n",
        "        self.conv2 = resblock(64, 64, 3, 2)  # H/8  -  256D\n",
        "        self.conv3 = resblock(256, 128, 4, 2)  # H/16 -  512D\n",
        "        self.conv4 = resblock(512, 256, 6, 2)  # H/32 - 1024D\n",
        "        self.conv5 = resblock(1024, 512, 3, 2)  # H/64 - 2048D\n",
        "\n",
        "        # decoder\n",
        "        self.upconv6 = upconv(2048, 512, 3, 2)\n",
        "        self.iconv6 = conv(1024 + 512, 512, 3, 1)\n",
        "\n",
        "        self.upconv5 = upconv(512, 256, 3, 2)\n",
        "        self.iconv5 = conv(512+256, 256, 3, 1)\n",
        "\n",
        "        self.upconv4 = upconv(256, 128, 3, 2)\n",
        "        self.iconv4 = conv(256+128, 128, 3, 1)\n",
        "        self.disp4_layer = get_disp(128)\n",
        "\n",
        "        self.upconv3 = upconv(128, 64, 3, 2)\n",
        "        self.iconv3 = conv(64+64+2, 64, 3, 1)\n",
        "        self.disp3_layer = get_disp(64)\n",
        "\n",
        "        self.upconv2 = upconv(64, 32, 3, 2)\n",
        "        self.iconv2 = conv(32+64+2, 32, 3, 1)\n",
        "        self.disp2_layer = get_disp(32)\n",
        "\n",
        "        self.upconv1 = upconv(32, 16, 3, 2)\n",
        "        self.iconv1 = conv(16+2, 16, 3, 1)\n",
        "        self.disp1_layer = get_disp(16)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder\n",
        "        x1 = self.conv1(x)\n",
        "        x_pool1 = self.pool1(x1)\n",
        "        x2 = self.conv2(x_pool1)\n",
        "        x3 = self.conv3(x2)\n",
        "        x4 = self.conv4(x3)\n",
        "        x5 = self.conv5(x4)\n",
        "\n",
        "        # skips\n",
        "        skip1 = x1\n",
        "        skip2 = x_pool1\n",
        "        skip3 = x2\n",
        "        skip4 = x3\n",
        "        skip5 = x4\n",
        "\n",
        "        # decoder\n",
        "        upconv6 = self.upconv6(x5)\n",
        "        concat6 = torch.cat((upconv6, skip5), 1)\n",
        "        iconv6 = self.iconv6(concat6)\n",
        "\n",
        "        upconv5 = self.upconv5(iconv6)\n",
        "        concat5 = torch.cat((upconv5, skip4), 1)\n",
        "        iconv5 = self.iconv5(concat5)\n",
        "\n",
        "        upconv4 = self.upconv4(iconv5)\n",
        "        concat4 = torch.cat((upconv4, skip3), 1)\n",
        "        iconv4 = self.iconv4(concat4)\n",
        "        self.disp4 = self.disp4_layer(iconv4)\n",
        "        self.udisp4 = nn.functional.interpolate(self.disp4, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        upconv3 = self.upconv3(iconv4)\n",
        "        concat3 = torch.cat((upconv3, skip2, self.udisp4), 1)\n",
        "        iconv3 = self.iconv3(concat3)\n",
        "        self.disp3 = self.disp3_layer(iconv3)\n",
        "        self.udisp3 = nn.functional.interpolate(self.disp3, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        upconv2 = self.upconv2(iconv3)\n",
        "        concat2 = torch.cat((upconv2, skip1, self.udisp3), 1)\n",
        "        iconv2 = self.iconv2(concat2)\n",
        "        self.disp2 = self.disp2_layer(iconv2)\n",
        "        self.udisp2 = nn.functional.interpolate(self.disp2, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        upconv1 = self.upconv1(iconv2)\n",
        "        concat1 = torch.cat((upconv1, self.udisp2), 1)\n",
        "        iconv1 = self.iconv1(concat1)\n",
        "        self.disp1 = self.disp1_layer(iconv1)\n",
        "        return self.disp1, self.disp2, self.disp3, self.disp4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32d7FCVUWsAT",
        "colab_type": "code",
        "outputId": "8abd8b66-96a3-4d32-8118-12d5d9fb1704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "summary(Resnet50_md(3).to(device), (3, 192, 192))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 96, 96]           9,472\n",
            "       BatchNorm2d-2           [-1, 64, 96, 96]             128\n",
            "              conv-3           [-1, 64, 96, 96]               0\n",
            "           maxpool-4           [-1, 64, 48, 48]               0\n",
            "            Conv2d-5           [-1, 64, 48, 48]           4,160\n",
            "       BatchNorm2d-6           [-1, 64, 48, 48]             128\n",
            "              conv-7           [-1, 64, 48, 48]               0\n",
            "            Conv2d-8           [-1, 64, 24, 24]          36,928\n",
            "       BatchNorm2d-9           [-1, 64, 24, 24]             128\n",
            "             conv-10           [-1, 64, 24, 24]               0\n",
            "           Conv2d-11          [-1, 256, 24, 24]          16,640\n",
            "           Conv2d-12          [-1, 256, 24, 24]          16,640\n",
            "      BatchNorm2d-13          [-1, 256, 24, 24]             512\n",
            "          resconv-14          [-1, 256, 24, 24]               0\n",
            "           Conv2d-15           [-1, 64, 24, 24]          16,448\n",
            "      BatchNorm2d-16           [-1, 64, 24, 24]             128\n",
            "             conv-17           [-1, 64, 24, 24]               0\n",
            "           Conv2d-18           [-1, 64, 24, 24]          36,928\n",
            "      BatchNorm2d-19           [-1, 64, 24, 24]             128\n",
            "             conv-20           [-1, 64, 24, 24]               0\n",
            "           Conv2d-21          [-1, 256, 24, 24]          16,640\n",
            "           Conv2d-22          [-1, 256, 24, 24]          65,792\n",
            "      BatchNorm2d-23          [-1, 256, 24, 24]             512\n",
            "          resconv-24          [-1, 256, 24, 24]               0\n",
            "           Conv2d-25           [-1, 64, 24, 24]          16,448\n",
            "      BatchNorm2d-26           [-1, 64, 24, 24]             128\n",
            "             conv-27           [-1, 64, 24, 24]               0\n",
            "           Conv2d-28           [-1, 64, 24, 24]          36,928\n",
            "      BatchNorm2d-29           [-1, 64, 24, 24]             128\n",
            "             conv-30           [-1, 64, 24, 24]               0\n",
            "           Conv2d-31          [-1, 256, 24, 24]          16,640\n",
            "           Conv2d-32          [-1, 256, 24, 24]          65,792\n",
            "      BatchNorm2d-33          [-1, 256, 24, 24]             512\n",
            "          resconv-34          [-1, 256, 24, 24]               0\n",
            "           Conv2d-35          [-1, 128, 24, 24]          32,896\n",
            "      BatchNorm2d-36          [-1, 128, 24, 24]             256\n",
            "             conv-37          [-1, 128, 24, 24]               0\n",
            "           Conv2d-38          [-1, 128, 12, 12]         147,584\n",
            "      BatchNorm2d-39          [-1, 128, 12, 12]             256\n",
            "             conv-40          [-1, 128, 12, 12]               0\n",
            "           Conv2d-41          [-1, 512, 12, 12]          66,048\n",
            "           Conv2d-42          [-1, 512, 12, 12]         131,584\n",
            "      BatchNorm2d-43          [-1, 512, 12, 12]           1,024\n",
            "          resconv-44          [-1, 512, 12, 12]               0\n",
            "           Conv2d-45          [-1, 128, 12, 12]          65,664\n",
            "      BatchNorm2d-46          [-1, 128, 12, 12]             256\n",
            "             conv-47          [-1, 128, 12, 12]               0\n",
            "           Conv2d-48          [-1, 128, 12, 12]         147,584\n",
            "      BatchNorm2d-49          [-1, 128, 12, 12]             256\n",
            "             conv-50          [-1, 128, 12, 12]               0\n",
            "           Conv2d-51          [-1, 512, 12, 12]          66,048\n",
            "           Conv2d-52          [-1, 512, 12, 12]         262,656\n",
            "      BatchNorm2d-53          [-1, 512, 12, 12]           1,024\n",
            "          resconv-54          [-1, 512, 12, 12]               0\n",
            "           Conv2d-55          [-1, 128, 12, 12]          65,664\n",
            "      BatchNorm2d-56          [-1, 128, 12, 12]             256\n",
            "             conv-57          [-1, 128, 12, 12]               0\n",
            "           Conv2d-58          [-1, 128, 12, 12]         147,584\n",
            "      BatchNorm2d-59          [-1, 128, 12, 12]             256\n",
            "             conv-60          [-1, 128, 12, 12]               0\n",
            "           Conv2d-61          [-1, 512, 12, 12]          66,048\n",
            "           Conv2d-62          [-1, 512, 12, 12]         262,656\n",
            "      BatchNorm2d-63          [-1, 512, 12, 12]           1,024\n",
            "          resconv-64          [-1, 512, 12, 12]               0\n",
            "           Conv2d-65          [-1, 128, 12, 12]          65,664\n",
            "      BatchNorm2d-66          [-1, 128, 12, 12]             256\n",
            "             conv-67          [-1, 128, 12, 12]               0\n",
            "           Conv2d-68          [-1, 128, 12, 12]         147,584\n",
            "      BatchNorm2d-69          [-1, 128, 12, 12]             256\n",
            "             conv-70          [-1, 128, 12, 12]               0\n",
            "           Conv2d-71          [-1, 512, 12, 12]          66,048\n",
            "           Conv2d-72          [-1, 512, 12, 12]         262,656\n",
            "      BatchNorm2d-73          [-1, 512, 12, 12]           1,024\n",
            "          resconv-74          [-1, 512, 12, 12]               0\n",
            "           Conv2d-75          [-1, 256, 12, 12]         131,328\n",
            "      BatchNorm2d-76          [-1, 256, 12, 12]             512\n",
            "             conv-77          [-1, 256, 12, 12]               0\n",
            "           Conv2d-78            [-1, 256, 6, 6]         590,080\n",
            "      BatchNorm2d-79            [-1, 256, 6, 6]             512\n",
            "             conv-80            [-1, 256, 6, 6]               0\n",
            "           Conv2d-81           [-1, 1024, 6, 6]         263,168\n",
            "           Conv2d-82           [-1, 1024, 6, 6]         525,312\n",
            "      BatchNorm2d-83           [-1, 1024, 6, 6]           2,048\n",
            "          resconv-84           [-1, 1024, 6, 6]               0\n",
            "           Conv2d-85            [-1, 256, 6, 6]         262,400\n",
            "      BatchNorm2d-86            [-1, 256, 6, 6]             512\n",
            "             conv-87            [-1, 256, 6, 6]               0\n",
            "           Conv2d-88            [-1, 256, 6, 6]         590,080\n",
            "      BatchNorm2d-89            [-1, 256, 6, 6]             512\n",
            "             conv-90            [-1, 256, 6, 6]               0\n",
            "           Conv2d-91           [-1, 1024, 6, 6]         263,168\n",
            "           Conv2d-92           [-1, 1024, 6, 6]       1,049,600\n",
            "      BatchNorm2d-93           [-1, 1024, 6, 6]           2,048\n",
            "          resconv-94           [-1, 1024, 6, 6]               0\n",
            "           Conv2d-95            [-1, 256, 6, 6]         262,400\n",
            "      BatchNorm2d-96            [-1, 256, 6, 6]             512\n",
            "             conv-97            [-1, 256, 6, 6]               0\n",
            "           Conv2d-98            [-1, 256, 6, 6]         590,080\n",
            "      BatchNorm2d-99            [-1, 256, 6, 6]             512\n",
            "            conv-100            [-1, 256, 6, 6]               0\n",
            "          Conv2d-101           [-1, 1024, 6, 6]         263,168\n",
            "          Conv2d-102           [-1, 1024, 6, 6]       1,049,600\n",
            "     BatchNorm2d-103           [-1, 1024, 6, 6]           2,048\n",
            "         resconv-104           [-1, 1024, 6, 6]               0\n",
            "          Conv2d-105            [-1, 256, 6, 6]         262,400\n",
            "     BatchNorm2d-106            [-1, 256, 6, 6]             512\n",
            "            conv-107            [-1, 256, 6, 6]               0\n",
            "          Conv2d-108            [-1, 256, 6, 6]         590,080\n",
            "     BatchNorm2d-109            [-1, 256, 6, 6]             512\n",
            "            conv-110            [-1, 256, 6, 6]               0\n",
            "          Conv2d-111           [-1, 1024, 6, 6]         263,168\n",
            "          Conv2d-112           [-1, 1024, 6, 6]       1,049,600\n",
            "     BatchNorm2d-113           [-1, 1024, 6, 6]           2,048\n",
            "         resconv-114           [-1, 1024, 6, 6]               0\n",
            "          Conv2d-115            [-1, 256, 6, 6]         262,400\n",
            "     BatchNorm2d-116            [-1, 256, 6, 6]             512\n",
            "            conv-117            [-1, 256, 6, 6]               0\n",
            "          Conv2d-118            [-1, 256, 6, 6]         590,080\n",
            "     BatchNorm2d-119            [-1, 256, 6, 6]             512\n",
            "            conv-120            [-1, 256, 6, 6]               0\n",
            "          Conv2d-121           [-1, 1024, 6, 6]         263,168\n",
            "          Conv2d-122           [-1, 1024, 6, 6]       1,049,600\n",
            "     BatchNorm2d-123           [-1, 1024, 6, 6]           2,048\n",
            "         resconv-124           [-1, 1024, 6, 6]               0\n",
            "          Conv2d-125            [-1, 256, 6, 6]         262,400\n",
            "     BatchNorm2d-126            [-1, 256, 6, 6]             512\n",
            "            conv-127            [-1, 256, 6, 6]               0\n",
            "          Conv2d-128            [-1, 256, 6, 6]         590,080\n",
            "     BatchNorm2d-129            [-1, 256, 6, 6]             512\n",
            "            conv-130            [-1, 256, 6, 6]               0\n",
            "          Conv2d-131           [-1, 1024, 6, 6]         263,168\n",
            "          Conv2d-132           [-1, 1024, 6, 6]       1,049,600\n",
            "     BatchNorm2d-133           [-1, 1024, 6, 6]           2,048\n",
            "         resconv-134           [-1, 1024, 6, 6]               0\n",
            "          Conv2d-135            [-1, 512, 6, 6]         524,800\n",
            "     BatchNorm2d-136            [-1, 512, 6, 6]           1,024\n",
            "            conv-137            [-1, 512, 6, 6]               0\n",
            "          Conv2d-138            [-1, 512, 3, 3]       2,359,808\n",
            "     BatchNorm2d-139            [-1, 512, 3, 3]           1,024\n",
            "            conv-140            [-1, 512, 3, 3]               0\n",
            "          Conv2d-141           [-1, 2048, 3, 3]       1,050,624\n",
            "          Conv2d-142           [-1, 2048, 3, 3]       2,099,200\n",
            "     BatchNorm2d-143           [-1, 2048, 3, 3]           4,096\n",
            "         resconv-144           [-1, 2048, 3, 3]               0\n",
            "          Conv2d-145            [-1, 512, 3, 3]       1,049,088\n",
            "     BatchNorm2d-146            [-1, 512, 3, 3]           1,024\n",
            "            conv-147            [-1, 512, 3, 3]               0\n",
            "          Conv2d-148            [-1, 512, 3, 3]       2,359,808\n",
            "     BatchNorm2d-149            [-1, 512, 3, 3]           1,024\n",
            "            conv-150            [-1, 512, 3, 3]               0\n",
            "          Conv2d-151           [-1, 2048, 3, 3]       1,050,624\n",
            "          Conv2d-152           [-1, 2048, 3, 3]       4,196,352\n",
            "     BatchNorm2d-153           [-1, 2048, 3, 3]           4,096\n",
            "         resconv-154           [-1, 2048, 3, 3]               0\n",
            "          Conv2d-155            [-1, 512, 3, 3]       1,049,088\n",
            "     BatchNorm2d-156            [-1, 512, 3, 3]           1,024\n",
            "            conv-157            [-1, 512, 3, 3]               0\n",
            "          Conv2d-158            [-1, 512, 3, 3]       2,359,808\n",
            "     BatchNorm2d-159            [-1, 512, 3, 3]           1,024\n",
            "            conv-160            [-1, 512, 3, 3]               0\n",
            "          Conv2d-161           [-1, 2048, 3, 3]       1,050,624\n",
            "          Conv2d-162           [-1, 2048, 3, 3]       4,196,352\n",
            "     BatchNorm2d-163           [-1, 2048, 3, 3]           4,096\n",
            "         resconv-164           [-1, 2048, 3, 3]               0\n",
            "          Conv2d-165            [-1, 512, 6, 6]       9,437,696\n",
            "     BatchNorm2d-166            [-1, 512, 6, 6]           1,024\n",
            "            conv-167            [-1, 512, 6, 6]               0\n",
            "          upconv-168            [-1, 512, 6, 6]               0\n",
            "          Conv2d-169            [-1, 512, 6, 6]       7,078,400\n",
            "     BatchNorm2d-170            [-1, 512, 6, 6]           1,024\n",
            "            conv-171            [-1, 512, 6, 6]               0\n",
            "          Conv2d-172          [-1, 256, 12, 12]       1,179,904\n",
            "     BatchNorm2d-173          [-1, 256, 12, 12]             512\n",
            "            conv-174          [-1, 256, 12, 12]               0\n",
            "          upconv-175          [-1, 256, 12, 12]               0\n",
            "          Conv2d-176          [-1, 256, 12, 12]       1,769,728\n",
            "     BatchNorm2d-177          [-1, 256, 12, 12]             512\n",
            "            conv-178          [-1, 256, 12, 12]               0\n",
            "          Conv2d-179          [-1, 128, 24, 24]         295,040\n",
            "     BatchNorm2d-180          [-1, 128, 24, 24]             256\n",
            "            conv-181          [-1, 128, 24, 24]               0\n",
            "          upconv-182          [-1, 128, 24, 24]               0\n",
            "          Conv2d-183          [-1, 128, 24, 24]         442,496\n",
            "     BatchNorm2d-184          [-1, 128, 24, 24]             256\n",
            "            conv-185          [-1, 128, 24, 24]               0\n",
            "          Conv2d-186            [-1, 2, 24, 24]           2,306\n",
            "     BatchNorm2d-187            [-1, 2, 24, 24]               4\n",
            "         Sigmoid-188            [-1, 2, 24, 24]               0\n",
            "        get_disp-189            [-1, 2, 24, 24]               0\n",
            "          Conv2d-190           [-1, 64, 48, 48]          73,792\n",
            "     BatchNorm2d-191           [-1, 64, 48, 48]             128\n",
            "            conv-192           [-1, 64, 48, 48]               0\n",
            "          upconv-193           [-1, 64, 48, 48]               0\n",
            "          Conv2d-194           [-1, 64, 48, 48]          74,944\n",
            "     BatchNorm2d-195           [-1, 64, 48, 48]             128\n",
            "            conv-196           [-1, 64, 48, 48]               0\n",
            "          Conv2d-197            [-1, 2, 48, 48]           1,154\n",
            "     BatchNorm2d-198            [-1, 2, 48, 48]               4\n",
            "         Sigmoid-199            [-1, 2, 48, 48]               0\n",
            "        get_disp-200            [-1, 2, 48, 48]               0\n",
            "          Conv2d-201           [-1, 32, 96, 96]          18,464\n",
            "     BatchNorm2d-202           [-1, 32, 96, 96]              64\n",
            "            conv-203           [-1, 32, 96, 96]               0\n",
            "          upconv-204           [-1, 32, 96, 96]               0\n",
            "          Conv2d-205           [-1, 32, 96, 96]          28,256\n",
            "     BatchNorm2d-206           [-1, 32, 96, 96]              64\n",
            "            conv-207           [-1, 32, 96, 96]               0\n",
            "          Conv2d-208            [-1, 2, 96, 96]             578\n",
            "     BatchNorm2d-209            [-1, 2, 96, 96]               4\n",
            "         Sigmoid-210            [-1, 2, 96, 96]               0\n",
            "        get_disp-211            [-1, 2, 96, 96]               0\n",
            "          Conv2d-212         [-1, 16, 192, 192]           4,624\n",
            "     BatchNorm2d-213         [-1, 16, 192, 192]              32\n",
            "            conv-214         [-1, 16, 192, 192]               0\n",
            "          upconv-215         [-1, 16, 192, 192]               0\n",
            "          Conv2d-216         [-1, 16, 192, 192]           2,608\n",
            "     BatchNorm2d-217         [-1, 16, 192, 192]              32\n",
            "            conv-218         [-1, 16, 192, 192]               0\n",
            "          Conv2d-219          [-1, 2, 192, 192]             290\n",
            "     BatchNorm2d-220          [-1, 2, 192, 192]               4\n",
            "         Sigmoid-221          [-1, 2, 192, 192]               0\n",
            "        get_disp-222          [-1, 2, 192, 192]               0\n",
            "================================================================\n",
            "Total params: 58,501,496\n",
            "Trainable params: 58,501,496\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.42\n",
            "Forward/backward pass size (MB): 126.91\n",
            "Params size (MB): 223.17\n",
            "Estimated Total Size (MB): 350.50\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaMeH5iSW1DM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Resnet50_md(3)\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rglqcc4se35O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Resnet50_md(3)\n",
        "model = model.to(device)\n",
        "\n",
        "model.train()\n",
        "for i in tqdm(range(1000)):\n",
        "    input = torch.randn(128, 3, 192, 192)\n",
        "    input = input.to(device)\n",
        "\n",
        "    model(input)\n",
        "\n",
        "    del input\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FENShq9YJbi",
        "colab_type": "code",
        "outputId": "81e710ef-50b4-492b-ea21-00acb442759f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.memory_allocated()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxvC0IXbYP52",
        "colab_type": "code",
        "outputId": "33c603a0-52b4-4b89-8563-e80cc49821c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "del input"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-691fe59cfe1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'input' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU9LVLaEYS0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nznY2KSwYq7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class ResDoubleConv(nn.Module):\n",
        "    '''Basic DoubleConv of a ResNetV2'''\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResDoubleConv, self).__init__()\n",
        "\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels,\n",
        "                      kernel_size=3, padding=1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.double_conv(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResDownBlock(nn.Module):\n",
        "    '''Basic DownBlock of a ResNetV2'''\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResDownBlock, self).__init__()\n",
        "\n",
        "        self.double_conv = ResDoubleConv(in_channels, out_channels)\n",
        "\n",
        "        self.proj_layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "        self.down_sample = nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self, input):\n",
        "        identity = self.proj_layer(input)\n",
        "        out = self.double_conv(input)\n",
        "        out = out + identity\n",
        "\n",
        "        return self.down_sample(out), out\n",
        "\n",
        "\n",
        "class ResUpBlock(nn.Module):\n",
        "    '''Basic UpBlock of a ResNetV2'''\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResUpBlock, self).__init__()\n",
        "\n",
        "        self.upsample_1 = nn.PixelShuffle(2)\n",
        "        self.upsample_2 = nn.PixelShuffle(2)\n",
        "        self.upsample_3 = nn.PixelShuffle(2)\n",
        "        self.upsample_4 = nn.PixelShuffle(2)\n",
        "\n",
        "        self.double_conv = ResDoubleConv(in_channels, out_channels)\n",
        "\n",
        "        self.proj_layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, down_input, skip_input, decoder_input=None):\n",
        "\n",
        "        upsampled = [self.upsample_1(down_input), self.upsample_2(\n",
        "            down_input), self.upsample_3(down_input), self.upsample_4(down_input)]\n",
        "        x = torch.cat(upsampled, dim=1)\n",
        "        x = torch.cat([x, skip_input], dim=1)\n",
        "\n",
        "        if decoder_input is not None:\n",
        "            x = torch.cat([x, decoder_input], dim=1)\n",
        "\n",
        "        identity = self.proj_layer(x)\n",
        "\n",
        "        out = self.double_conv(x) + identity\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResUNet, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        # H / 2   ; input = 192x192x6 ; output = 96x96x64   ; skip1 = 192x192x64\n",
        "        self.res_down1 = ResDownBlock(6, 64)\n",
        "        # H / 4   ; input = 96x96x64  ; output = 48x48x128  ; skip2 = 96x96x128\n",
        "        self.res_down2 = ResDownBlock(64, 128)\n",
        "        # H / 8   ; input = 48x48x128 ; output = 24x24x256  ; skip3 = 48x48x256\n",
        "        self.res_down3 = ResDownBlock(128, 256)\n",
        "        # H / 16  ; input = 24x24x256 ; output = 12x12x512  ; skip4 = 24x24x512\n",
        "        self.res_down4 = ResDownBlock(256, 512)\n",
        "\n",
        "        # Bridge\n",
        "        self.bridge = ResDoubleConv(512, 512)\n",
        "\n",
        "        # Depth Decoder\n",
        "        # H / 8  ; input = 24x24x1024(upscaled)  24x24x512(skip4)  ; output = 24x24x512(dskip4)\n",
        "        self.d_res_up4 = ResUpBlock(512 + 512, 512)\n",
        "        # H / 4  ; input = 48x48x512(upscaled)   48x48x256(skip3)  ; output = 48x48x256(dskip3)\n",
        "        self.d_res_up3 = ResUpBlock(512 + 256, 256)\n",
        "        # H / 2  ; input = 96x96x256(upscaled)   96x96x128(skip2)  ; output = 96x96x128(dskip2)\n",
        "        self.d_res_up2 = ResUpBlock(256 + 128, 128)\n",
        "        # H / 1  ; input = 192x192x128(upscaled) 192x192x64(skip1) ; output = 192x192x64(dskip1)\n",
        "        self.d_res_up1 = ResUpBlock(128 + 64, 64)\n",
        "\n",
        "        # Depth Output\n",
        "        self.depth_output = nn.Conv2d(\n",
        "            64, 1, kernel_size=1, stride=1, bias=False)  # output = 192x192x1\n",
        "\n",
        "        # Segmentation Decoder\n",
        "        # H / 8  ; input = 24x24x1024(upscaled)  24x24x512(dskip4)  24x24x512(skip4)  ; output = 24x24x512\n",
        "        self.s_res_up4 = ResUpBlock(512 + 512 + 512, 512)\n",
        "        # H / 4  ; input = 48x48x512(upscaled)   48x48x256(dskip3)  48x48x256(skip3)  ; output = 48x48x256\n",
        "        self.s_res_up3 = ResUpBlock(512 + 256 + 256, 256)\n",
        "        # H / 2  ; input = 96x96x256(upscaled)   96x96x128(dskip2)  96x96x128(skip2)  ; output = 96x96x128\n",
        "        self.s_res_up2 = ResUpBlock(256 + 128 + 128, 128)\n",
        "        # H / 1  ; input = 192x192x128(upscaled) 192x192x64(dskip1) 192x192x64(skip1) ; output = 192x192x64\n",
        "        self.s_res_up1 = ResUpBlock(128 + 64 + 64, 64)\n",
        "\n",
        "        # Segmentation Output\n",
        "        self.segment_output = nn.Conv2d(\n",
        "            64, 1, kernel_size=1, stride=1, bias=False)  # output = 192x192x1\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        # Encoder\n",
        "        rd1, skip1_out = self.res_down1(input)\n",
        "        rd2, skip2_out = self.res_down2(rd1)\n",
        "        rd3, skip3_out = self.res_down3(rd2)\n",
        "        rd4, skip4_out = self.res_down4(rd3)\n",
        "\n",
        "        # Bridge\n",
        "        bridge = self.bridge(rd4)\n",
        "\n",
        "        # Depth Decoder\n",
        "        dru4 = self.d_res_up4(bridge, skip4_out)\n",
        "        dru3 = self.d_res_up3(dru4, skip3_out)\n",
        "        dru2 = self.d_res_up2(dru3, skip2_out)\n",
        "        dru1 = self.d_res_up1(dru2, skip1_out)\n",
        "\n",
        "        d_out = self.depth_output(dru1)\n",
        "\n",
        "        # Segmentation Decoder\n",
        "        sru4 = self.s_res_up4(bridge, skip4_out, dru4)\n",
        "        sru3 = self.s_res_up3(sru4, skip3_out, dru3)\n",
        "        sru2 = self.s_res_up2(sru3, skip2_out, dru2)\n",
        "        sru1 = self.s_res_up1(sru2, skip1_out, dru1)\n",
        "\n",
        "        s_out = self.segment_output(sru1)\n",
        "        return d_out, s_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zSe24oPZVdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ResUNet().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua7scQqIZZgs",
        "colab_type": "code",
        "outputId": "04e1007b-c2f0-4b71-f2f6-703a017269ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "summary(model, (6, 192, 192))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 192, 192]             384\n",
            "       BatchNorm2d-2         [-1, 64, 192, 192]             128\n",
            "       BatchNorm2d-3          [-1, 6, 192, 192]              12\n",
            "              ReLU-4          [-1, 6, 192, 192]               0\n",
            "            Conv2d-5         [-1, 64, 192, 192]           3,456\n",
            "       BatchNorm2d-6         [-1, 64, 192, 192]             128\n",
            "              ReLU-7         [-1, 64, 192, 192]               0\n",
            "            Conv2d-8         [-1, 64, 192, 192]          36,864\n",
            "     ResDoubleConv-9         [-1, 64, 192, 192]               0\n",
            "        MaxPool2d-10           [-1, 64, 96, 96]               0\n",
            "     ResDownBlock-11  [[-1, 64, 96, 96], [-1, 64, 192, 192]]               0\n",
            "           Conv2d-12          [-1, 128, 96, 96]           8,192\n",
            "      BatchNorm2d-13          [-1, 128, 96, 96]             256\n",
            "      BatchNorm2d-14           [-1, 64, 96, 96]             128\n",
            "             ReLU-15           [-1, 64, 96, 96]               0\n",
            "           Conv2d-16          [-1, 128, 96, 96]          73,728\n",
            "      BatchNorm2d-17          [-1, 128, 96, 96]             256\n",
            "             ReLU-18          [-1, 128, 96, 96]               0\n",
            "           Conv2d-19          [-1, 128, 96, 96]         147,456\n",
            "    ResDoubleConv-20          [-1, 128, 96, 96]               0\n",
            "        MaxPool2d-21          [-1, 128, 48, 48]               0\n",
            "     ResDownBlock-22  [[-1, 128, 48, 48], [-1, 128, 96, 96]]               0\n",
            "           Conv2d-23          [-1, 256, 48, 48]          32,768\n",
            "      BatchNorm2d-24          [-1, 256, 48, 48]             512\n",
            "      BatchNorm2d-25          [-1, 128, 48, 48]             256\n",
            "             ReLU-26          [-1, 128, 48, 48]               0\n",
            "           Conv2d-27          [-1, 256, 48, 48]         294,912\n",
            "      BatchNorm2d-28          [-1, 256, 48, 48]             512\n",
            "             ReLU-29          [-1, 256, 48, 48]               0\n",
            "           Conv2d-30          [-1, 256, 48, 48]         589,824\n",
            "    ResDoubleConv-31          [-1, 256, 48, 48]               0\n",
            "        MaxPool2d-32          [-1, 256, 24, 24]               0\n",
            "     ResDownBlock-33  [[-1, 256, 24, 24], [-1, 256, 48, 48]]               0\n",
            "           Conv2d-34          [-1, 512, 24, 24]         131,072\n",
            "      BatchNorm2d-35          [-1, 512, 24, 24]           1,024\n",
            "      BatchNorm2d-36          [-1, 256, 24, 24]             512\n",
            "             ReLU-37          [-1, 256, 24, 24]               0\n",
            "           Conv2d-38          [-1, 512, 24, 24]       1,179,648\n",
            "      BatchNorm2d-39          [-1, 512, 24, 24]           1,024\n",
            "             ReLU-40          [-1, 512, 24, 24]               0\n",
            "           Conv2d-41          [-1, 512, 24, 24]       2,359,296\n",
            "    ResDoubleConv-42          [-1, 512, 24, 24]               0\n",
            "        MaxPool2d-43          [-1, 512, 12, 12]               0\n",
            "     ResDownBlock-44  [[-1, 512, 12, 12], [-1, 512, 24, 24]]               0\n",
            "      BatchNorm2d-45          [-1, 512, 12, 12]           1,024\n",
            "             ReLU-46          [-1, 512, 12, 12]               0\n",
            "           Conv2d-47          [-1, 512, 12, 12]       2,359,296\n",
            "      BatchNorm2d-48          [-1, 512, 12, 12]           1,024\n",
            "             ReLU-49          [-1, 512, 12, 12]               0\n",
            "           Conv2d-50          [-1, 512, 12, 12]       2,359,296\n",
            "    ResDoubleConv-51          [-1, 512, 12, 12]               0\n",
            "     PixelShuffle-52          [-1, 128, 24, 24]               0\n",
            "     PixelShuffle-53          [-1, 128, 24, 24]               0\n",
            "     PixelShuffle-54          [-1, 128, 24, 24]               0\n",
            "     PixelShuffle-55          [-1, 128, 24, 24]               0\n",
            "           Conv2d-56          [-1, 512, 24, 24]         524,288\n",
            "      BatchNorm2d-57          [-1, 512, 24, 24]           1,024\n",
            "      BatchNorm2d-58         [-1, 1024, 24, 24]           2,048\n",
            "             ReLU-59         [-1, 1024, 24, 24]               0\n",
            "           Conv2d-60          [-1, 512, 24, 24]       4,718,592\n",
            "      BatchNorm2d-61          [-1, 512, 24, 24]           1,024\n",
            "             ReLU-62          [-1, 512, 24, 24]               0\n",
            "           Conv2d-63          [-1, 512, 24, 24]       2,359,296\n",
            "    ResDoubleConv-64          [-1, 512, 24, 24]               0\n",
            "       ResUpBlock-65          [-1, 512, 24, 24]               0\n",
            "     PixelShuffle-66          [-1, 128, 48, 48]               0\n",
            "     PixelShuffle-67          [-1, 128, 48, 48]               0\n",
            "     PixelShuffle-68          [-1, 128, 48, 48]               0\n",
            "     PixelShuffle-69          [-1, 128, 48, 48]               0\n",
            "           Conv2d-70          [-1, 256, 48, 48]         196,608\n",
            "      BatchNorm2d-71          [-1, 256, 48, 48]             512\n",
            "      BatchNorm2d-72          [-1, 768, 48, 48]           1,536\n",
            "             ReLU-73          [-1, 768, 48, 48]               0\n",
            "           Conv2d-74          [-1, 256, 48, 48]       1,769,472\n",
            "      BatchNorm2d-75          [-1, 256, 48, 48]             512\n",
            "             ReLU-76          [-1, 256, 48, 48]               0\n",
            "           Conv2d-77          [-1, 256, 48, 48]         589,824\n",
            "    ResDoubleConv-78          [-1, 256, 48, 48]               0\n",
            "       ResUpBlock-79          [-1, 256, 48, 48]               0\n",
            "     PixelShuffle-80           [-1, 64, 96, 96]               0\n",
            "     PixelShuffle-81           [-1, 64, 96, 96]               0\n",
            "     PixelShuffle-82           [-1, 64, 96, 96]               0\n",
            "     PixelShuffle-83           [-1, 64, 96, 96]               0\n",
            "           Conv2d-84          [-1, 128, 96, 96]          49,152\n",
            "      BatchNorm2d-85          [-1, 128, 96, 96]             256\n",
            "      BatchNorm2d-86          [-1, 384, 96, 96]             768\n",
            "             ReLU-87          [-1, 384, 96, 96]               0\n",
            "           Conv2d-88          [-1, 128, 96, 96]         442,368\n",
            "      BatchNorm2d-89          [-1, 128, 96, 96]             256\n",
            "             ReLU-90          [-1, 128, 96, 96]               0\n",
            "           Conv2d-91          [-1, 128, 96, 96]         147,456\n",
            "    ResDoubleConv-92          [-1, 128, 96, 96]               0\n",
            "       ResUpBlock-93          [-1, 128, 96, 96]               0\n",
            "     PixelShuffle-94         [-1, 32, 192, 192]               0\n",
            "     PixelShuffle-95         [-1, 32, 192, 192]               0\n",
            "     PixelShuffle-96         [-1, 32, 192, 192]               0\n",
            "     PixelShuffle-97         [-1, 32, 192, 192]               0\n",
            "           Conv2d-98         [-1, 64, 192, 192]          12,288\n",
            "      BatchNorm2d-99         [-1, 64, 192, 192]             128\n",
            "     BatchNorm2d-100        [-1, 192, 192, 192]             384\n",
            "            ReLU-101        [-1, 192, 192, 192]               0\n",
            "          Conv2d-102         [-1, 64, 192, 192]         110,592\n",
            "     BatchNorm2d-103         [-1, 64, 192, 192]             128\n",
            "            ReLU-104         [-1, 64, 192, 192]               0\n",
            "          Conv2d-105         [-1, 64, 192, 192]          36,864\n",
            "   ResDoubleConv-106         [-1, 64, 192, 192]               0\n",
            "      ResUpBlock-107         [-1, 64, 192, 192]               0\n",
            "          Conv2d-108          [-1, 1, 192, 192]              64\n",
            "    PixelShuffle-109          [-1, 128, 24, 24]               0\n",
            "    PixelShuffle-110          [-1, 128, 24, 24]               0\n",
            "    PixelShuffle-111          [-1, 128, 24, 24]               0\n",
            "    PixelShuffle-112          [-1, 128, 24, 24]               0\n",
            "          Conv2d-113          [-1, 512, 24, 24]         786,432\n",
            "     BatchNorm2d-114          [-1, 512, 24, 24]           1,024\n",
            "     BatchNorm2d-115         [-1, 1536, 24, 24]           3,072\n",
            "            ReLU-116         [-1, 1536, 24, 24]               0\n",
            "          Conv2d-117          [-1, 512, 24, 24]       7,077,888\n",
            "     BatchNorm2d-118          [-1, 512, 24, 24]           1,024\n",
            "            ReLU-119          [-1, 512, 24, 24]               0\n",
            "          Conv2d-120          [-1, 512, 24, 24]       2,359,296\n",
            "   ResDoubleConv-121          [-1, 512, 24, 24]               0\n",
            "      ResUpBlock-122          [-1, 512, 24, 24]               0\n",
            "    PixelShuffle-123          [-1, 128, 48, 48]               0\n",
            "    PixelShuffle-124          [-1, 128, 48, 48]               0\n",
            "    PixelShuffle-125          [-1, 128, 48, 48]               0\n",
            "    PixelShuffle-126          [-1, 128, 48, 48]               0\n",
            "          Conv2d-127          [-1, 256, 48, 48]         262,144\n",
            "     BatchNorm2d-128          [-1, 256, 48, 48]             512\n",
            "     BatchNorm2d-129         [-1, 1024, 48, 48]           2,048\n",
            "            ReLU-130         [-1, 1024, 48, 48]               0\n",
            "          Conv2d-131          [-1, 256, 48, 48]       2,359,296\n",
            "     BatchNorm2d-132          [-1, 256, 48, 48]             512\n",
            "            ReLU-133          [-1, 256, 48, 48]               0\n",
            "          Conv2d-134          [-1, 256, 48, 48]         589,824\n",
            "   ResDoubleConv-135          [-1, 256, 48, 48]               0\n",
            "      ResUpBlock-136          [-1, 256, 48, 48]               0\n",
            "    PixelShuffle-137           [-1, 64, 96, 96]               0\n",
            "    PixelShuffle-138           [-1, 64, 96, 96]               0\n",
            "    PixelShuffle-139           [-1, 64, 96, 96]               0\n",
            "    PixelShuffle-140           [-1, 64, 96, 96]               0\n",
            "          Conv2d-141          [-1, 128, 96, 96]          65,536\n",
            "     BatchNorm2d-142          [-1, 128, 96, 96]             256\n",
            "     BatchNorm2d-143          [-1, 512, 96, 96]           1,024\n",
            "            ReLU-144          [-1, 512, 96, 96]               0\n",
            "          Conv2d-145          [-1, 128, 96, 96]         589,824\n",
            "     BatchNorm2d-146          [-1, 128, 96, 96]             256\n",
            "            ReLU-147          [-1, 128, 96, 96]               0\n",
            "          Conv2d-148          [-1, 128, 96, 96]         147,456\n",
            "   ResDoubleConv-149          [-1, 128, 96, 96]               0\n",
            "      ResUpBlock-150          [-1, 128, 96, 96]               0\n",
            "    PixelShuffle-151         [-1, 32, 192, 192]               0\n",
            "    PixelShuffle-152         [-1, 32, 192, 192]               0\n",
            "    PixelShuffle-153         [-1, 32, 192, 192]               0\n",
            "    PixelShuffle-154         [-1, 32, 192, 192]               0\n",
            "          Conv2d-155         [-1, 64, 192, 192]          16,384\n",
            "     BatchNorm2d-156         [-1, 64, 192, 192]             128\n",
            "     BatchNorm2d-157        [-1, 256, 192, 192]             512\n",
            "            ReLU-158        [-1, 256, 192, 192]               0\n",
            "          Conv2d-159         [-1, 64, 192, 192]         147,456\n",
            "     BatchNorm2d-160         [-1, 64, 192, 192]             128\n",
            "            ReLU-161         [-1, 64, 192, 192]               0\n",
            "          Conv2d-162         [-1, 64, 192, 192]          36,864\n",
            "   ResDoubleConv-163         [-1, 64, 192, 192]               0\n",
            "      ResUpBlock-164         [-1, 64, 192, 192]               0\n",
            "          Conv2d-165          [-1, 1, 192, 192]              64\n",
            "================================================================\n",
            "Total params: 34,997,388\n",
            "Trainable params: 34,997,388\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.84\n",
            "Forward/backward pass size (MB): 14099077.69\n",
            "Params size (MB): 133.50\n",
            "Estimated Total Size (MB): 14099212.04\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiwIxYl-ZbVx",
        "colab_type": "code",
        "outputId": "d69520aa-3493-4b17-dd9a-ee9b236c352f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sum(p.numel() for p in model.parameters()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34997388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-qJgFgla6Pw",
        "colab_type": "code",
        "outputId": "b0e59a0b-4d40-4832-86ac-b58375f2b261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "34997388 * 4 / 1024/1024"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "133.5044403076172"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxDj3DR3bFt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}